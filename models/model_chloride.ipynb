{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "## Environment\n",
    "# Change main system path to be able to run code from src folder\n",
    "import sys\n",
    "p = sys.path[0]\n",
    "# Mac OS\n",
    "if sys.path[0].endswith('/models'):\n",
    "    main_path = p[:-len('/models')]\n",
    "sys.path[0] = main_path\n",
    "\n",
    "import os, gc, json \n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src import (config, fe, features, feature_selection, \n",
    "                 preprocess, training, model_selection)\n",
    "from src.fe import CreateFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (1570, 5)\n",
      "Train labels: (766, 11)\n",
      "Train labels: (293, 11)\n",
      "Submission: (804, 11)\n",
      "['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n",
      "Labels w/o SAM : (1047, 11)\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "# ===== LOAD DATA ======\n",
    "metadata = pd.read_csv(config.DATA_DIR + 'metadata.csv')\n",
    "print(f'Metadata: {metadata.shape}')\n",
    "\n",
    "train_labels = pd.read_csv(config.DATA_DIR + 'train_labels.csv')\n",
    "print(f'Train labels: {train_labels.shape}')\n",
    "\n",
    "valid_labels = pd.read_csv(config.DATA_DIR + 'val_labels.csv')\n",
    "print(f'Train labels: {valid_labels.shape}')\n",
    "\n",
    "# Combine train and valid labels\n",
    "trvl_labels = pd.concat([train_labels, valid_labels], axis = 0)\n",
    "\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "print(f'Submission: {submission.shape}')\n",
    "\n",
    "# ===== FILE PATHS OF SAMPLES =====\n",
    "train_files = metadata[metadata.split == 'train']['features_path'].to_dict()\n",
    "valid_files = metadata[metadata.split == 'val']['features_path'].to_dict()\n",
    "test_files = metadata[metadata.split == 'test']['features_path'].to_dict()\n",
    "# Train & Valid files\n",
    "trva_files = train_files.copy()\n",
    "trva_files.update(valid_files)\n",
    "# All files\n",
    "all_test_files = valid_files.copy()\n",
    "all_test_files.update(test_files)\n",
    "\n",
    "# Define SAM testbed files\n",
    "sam_files = metadata[(metadata.instrument_type == 'sam_testbed') & (metadata.split == 'train')]['features_path']\n",
    "sam_files = sam_files.to_dict()\n",
    "\n",
    "# Get the names of the target columns in a list\n",
    "target_labels_list = [i for i in train_labels.columns if i not in ['sample_id']]\n",
    "print(target_labels_list)\n",
    "\n",
    "# SAM testbed labels\n",
    "sam_labels = train_labels.drop(train_labels.tail(len(sam_files)).index)\n",
    "sam_labels = pd.concat([sam_labels, valid_labels], axis=0)\n",
    "print(f'Labels w/o SAM : {sam_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'chloride'\n",
    "# Base model features\n",
    "INITIAL_FTS = 'fts_mz_maxabun'\n",
    "INITIAL_CVLOSS = 0.171918\n",
    "# Features to add to the base model\n",
    "ALL_FTS_GROUPS = config.FTS_GROUPS\n",
    "MODEL_ALGO = 'XGB_opt'\n",
    "DF_TARGET = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TYPE = 'tr'\n",
    "\n",
    "# Save best model features: CV loss the lowest when compared to previous fitted model\n",
    "BEST_MODEL_FTS_GROUPS = [INITIAL_FTS]   # Name of a feature group included in the final model\n",
    "BEST_MODEL_FTS = []                     # Selected features after SFM if applied\n",
    "BEST_MODEL_CVLOSS = 0\n",
    "BEST_MODEL_VLOSS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train initial: (766, 99)\n",
      "Reading features: \u001b[33mfts_mz_maxabun_XGB_opt_tr_SFM_COLS.txt\u001b[0m\n",
      "No features added: \u001b[34m46\u001b[0m\n",
      "\u001b[32mX_train base: (766, 46)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inital X_train: base model features\n",
    "X_train = pd.read_csv(os.path.join(config.DATA_DIR_OUT, \n",
    "                                   INITIAL_FTS + '_' + SPLIT_TYPE + '.csv'))\n",
    "print(f'X_train initial: {X_train.shape}')\n",
    "initial_fts_path = INITIAL_FTS + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_SFM_COLS.txt'\n",
    "if os.path.exists(initial_fts_path):\n",
    "    print(f'Reading features:', colored(f'{initial_fts_path}', 'yellow'))\n",
    "    with open(initial_fts_path) as json_file:\n",
    "            initial_fts_dict = json.load(json_file)\n",
    "    BEST_MODEL_FTS = BEST_MODEL_FTS + initial_fts_dict[LABEL]\n",
    "    print(f'No features added:',colored(f'{len(initial_fts_dict[LABEL])}', 'blue'))\n",
    "else:\n",
    "    BEST_MODEL_FTS = BEST_MODEL_FTS + X_train.columns.tolist()\n",
    "    print(f'No features added:',colored(f'{len(X_train.columns.tolist())}', 'blue'))\n",
    "\n",
    "# Redefine X_train given new set of features\n",
    "X_train = X_train[BEST_MODEL_FTS].copy()\n",
    "print(colored(f'X_train base: {X_train.shape}', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_slope_tt\u001b[0m\n",
      "No features: \u001b[34m1\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 47)\u001b[0m\n",
      "CVloss \u001b[31m0.00558\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun']\n",
      "\u001b[35mBEST CV LOSS: 0.171918\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mz_spectra\u001b[0m\n",
      "No features: \u001b[34m10\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 56)\u001b[0m\n",
      "CVloss \u001b[31m0.01332\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun']\n",
      "\u001b[35mBEST CV LOSS: 0.171918\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mzstats\u001b[0m\n",
      "Reading features: fts_mzstats_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m85\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 131)\u001b[0m\n",
      "CVloss \u001b[31m0.02765\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun']\n",
      "\u001b[35mBEST CV LOSS: 0.171918\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mass_loss_tempb\u001b[0m\n",
      "No features: \u001b[34m16\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 62)\u001b[0m\n",
      "CVloss \u001b[31m0.01599\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun']\n",
      "\u001b[35mBEST CV LOSS: 0.171918\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_cntpk_mratt\u001b[0m\n",
      "Reading features: fts_cntpk_mratt_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m70\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 116)\u001b[0m\n",
      "CVloss \u001b[31m0.02094\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun']\n",
      "\u001b[35mBEST CV LOSS: 0.171918\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_topmz\u001b[0m\n",
      "No features: \u001b[34m3\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 49)\u001b[0m\n",
      "CVloss \u001b[32m-0.0\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz']\n",
      "No features added: 49\n",
      "\u001b[35mBEST CV LOSS: 0.1719141787483848\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_peak_widths\u001b[0m\n",
      "Reading features: fts_peak_widths_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m54\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 103)\u001b[0m\n",
      "CVloss \u001b[31m0.02777\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz']\n",
      "\u001b[35mBEST CV LOSS: 0.1719141787483848\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mra_tempmz\u001b[0m\n",
      "Reading features: fts_mra_tempmz_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m45\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 94)\u001b[0m\n",
      "CVloss \u001b[31m0.01321\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz']\n",
      "\u001b[35mBEST CV LOSS: 0.1719141787483848\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_lr_corr_mz4\u001b[0m\n",
      "Reading features: fts_lr_corr_mz4_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m1\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 50)\u001b[0m\n",
      "CVloss \u001b[32m-0.00156\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz', 'fts_lr_corr_mz4']\n",
      "No features added: 50\n",
      "\u001b[35mBEST CV LOSS: 0.17035001341611558\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_corr_mz4\u001b[0m\n",
      "Reading features: fts_corr_mz4_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m17\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 67)\u001b[0m\n",
      "CVloss \u001b[31m0.03826\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz', 'fts_lr_corr_mz4']\n",
      "\u001b[35mBEST CV LOSS: 0.17035001341611558\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mzstats\u001b[0m\n",
      "Reading features: fts_mzstats_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m85\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 135)\u001b[0m\n",
      "CVloss \u001b[31m0.02486\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz', 'fts_lr_corr_mz4']\n",
      "\u001b[35mBEST CV LOSS: 0.17035001341611558\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_mz_maxabun\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Feature group: \u001b[33mfts_range_abun_to_temp\u001b[0m\n",
      "Reading features: fts_range_abun_to_temp_XGB_opt_tr_SFM_COLS.txt\n",
      "No features: \u001b[34m154\u001b[0m\n",
      "\u001b[32mX_train temp: (766, 204)\u001b[0m\n",
      "CVloss \u001b[31m0.0044\u001b[0m\n",
      "BEST_MODEL_FTS_GROUPS: ['fts_mz_maxabun', 'fts_topmz', 'fts_lr_corr_mz4']\n",
      "\u001b[35mBEST CV LOSS: 0.17035001341611558\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Starting cv loss\n",
    "best_cv_loss = INITIAL_CVLOSS\n",
    "\n",
    "for FTS_GROUP in ALL_FTS_GROUPS:\n",
    "    print('-'*55)\n",
    "    print(f'Feature group:', colored(f'{FTS_GROUP}', 'yellow'))\n",
    "    \n",
    "    X_train_temp = X_train.copy()\n",
    "\n",
    "    # If the feature is not already included in the best model\n",
    "    if FTS_GROUP not in BEST_MODEL_FTS_GROUPS:\n",
    "        \n",
    "        # ----- Read in the features df -----\n",
    "        # TODO Add check if the fts are already in the df ot to add them twice\n",
    "        new_df = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_GROUP + '_' + SPLIT_TYPE + '.csv'))\n",
    "        new_df_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_GROUP + '_vlte.csv'))\n",
    "        # Filter with selected features if they exist\n",
    "        new_df_fts_path = FTS_GROUP + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_SFM_COLS.txt'\n",
    "        if os.path.exists(new_df_fts_path):\n",
    "            print(f'Reading features: {new_df_fts_path}')\n",
    "            with open(new_df_fts_path) as json_file:\n",
    "                    new_df_fts_dict = json.load(json_file)\n",
    "            new_features_list = new_df_fts_dict[LABEL]\n",
    "            new_df = new_df[new_features_list].copy()\n",
    "            no_features = len(new_features_list)\n",
    "            print(f'No features:',colored(f'{no_features}', 'blue'))\n",
    "        else:\n",
    "            new_features_list = new_df.columns.tolist()\n",
    "            no_features = len(new_features_list)\n",
    "            print(f'No features:',colored(f'{no_features}', 'blue'))\n",
    "\n",
    "        # Add the new features to existing X_train_temp and X_vlte_temp\n",
    "        X_train_temp = pd.concat([X_train_temp, new_df], axis=1)\n",
    "        print(colored(f'X_train temp: {X_train_temp.shape}', 'green'))\n",
    "        \n",
    "        # ----- CV TRAINING -----\n",
    "        # MODEL INFORMATION\n",
    "        logloss_avg = []    # Average value of log loss for each label\n",
    "        \n",
    "        # Target variable\n",
    "        y = DF_TARGET[LABEL].copy()\n",
    "        \n",
    "        # Define cross validation\n",
    "        cv = StratifiedKFold(n_splits = config.NO_CV_FOLDS,\n",
    "                             random_state =config.RANDOM_SEED,\n",
    "                             shuffle = True)\n",
    "\n",
    "        # CROSS VALIDATION TRAINING\n",
    "        oof_logloss = [] # Metric for each fold for one label\n",
    "\n",
    "        # Define the folds and train the model\n",
    "        for fold, (t_, v_) in enumerate(cv.split(X_train_temp, y)):\n",
    "            #print(colored(f'FOLD {fold+1}', 'magenta'))\n",
    "            Xtr = X_train_temp.iloc[t_].copy()\n",
    "            ytr = y.iloc[t_].values\n",
    "            Xval = X_train_temp.iloc[v_].copy()\n",
    "            yval = y.iloc[v_].values\n",
    "\n",
    "            clf = model_selection.models[MODEL_ALGO]\n",
    "            clf.fit(Xtr, ytr)\n",
    "            \n",
    "            # Compute predictions\n",
    "            y_preds = clf.predict_proba(Xval)[:,1]\n",
    "\n",
    "            # Compute model metric\n",
    "            oof_logloss.append(log_loss(yval, y_preds))\n",
    "        \n",
    "        # Average log loss per label\n",
    "        logloss_avg = np.sum(oof_logloss)/config.NO_CV_FOLDS\n",
    "        \n",
    "        # Compare CV losses\n",
    "        if logloss_avg < best_cv_loss:\n",
    "            print(f'CVloss',colored(f'{(np.round(logloss_avg-best_cv_loss,5))}', 'green'))\n",
    "            best_cv_loss = logloss_avg\n",
    "            \n",
    "            # Add feature group to BEST_MODEL_FTS_GROUPS\n",
    "            BEST_MODEL_FTS_GROUPS = BEST_MODEL_FTS_GROUPS + [FTS_GROUP]\n",
    "            print(f'BEST_MODEL_FTS_GROUPS: {BEST_MODEL_FTS_GROUPS}')\n",
    "            \n",
    "            # Add features to BEST_MODEL_FTS\n",
    "            BEST_MODEL_FTS = BEST_MODEL_FTS + new_features_list\n",
    "            print(f'No features added: {len(BEST_MODEL_FTS)}')\n",
    "            \n",
    "            # Copy the training dataset\n",
    "            X_train = X_train_temp.copy()\n",
    "        else:\n",
    "            print(f'CVloss',colored(f'{(np.round(logloss_avg-best_cv_loss,5))}', 'red'))\n",
    "            print(f'BEST_MODEL_FTS_GROUPS: {BEST_MODEL_FTS_GROUPS}')\n",
    "        \n",
    "        print(colored(f'BEST CV LOSS: {best_cv_loss}', 'magenta'))\n",
    "        \n",
    "        del X_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mX_train: (766, 50)\u001b[0m\n",
      "\u001b[32my_train: (766,)\u001b[0m\n",
      "\u001b[32mX_vlte: (804, 50)\u001b[0m\n",
      "\u001b[31mMODEL VLOSS: 0.24926533270468332\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Fit full model on BEST_MODEL\n",
    "\n",
    "y_train = train_labels[LABEL].values\n",
    "\n",
    "# Define validation & test dataset\n",
    "X_vlte = pd.DataFrame()\n",
    "for fg in BEST_MODEL_FTS_GROUPS:\n",
    "    df_tmp = pd.read_csv(os.path.join(config.DATA_DIR_OUT,\n",
    "                                  fg + '_vlte.csv'))\n",
    "    X_vlte = pd.concat([X_vlte, df_tmp], axis=1)\n",
    "    \n",
    "X_vlte = X_vlte[BEST_MODEL_FTS].copy()\n",
    "y_vlte = trvl_labels[LABEL]\n",
    "\n",
    "print(colored(f'X_train: {X_train.shape}', 'green'))\n",
    "print(colored(f'y_train: {y_train.shape}', 'green'))\n",
    "print(colored(f'X_vlte: {X_vlte.shape}', 'green'))\n",
    "\n",
    "clf = model_selection.models[MODEL_ALGO]\n",
    "clf.fit(X_train, y_train)\n",
    "        \n",
    "# Make predictions\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "submission[LABEL] = clf.predict_proba(X_vlte)[:,1]\n",
    "\n",
    "y_actual = valid_labels[LABEL]\n",
    "y_preds = submission[LABEL].iloc[:len(valid_files)]\n",
    "model_loss = log_loss(y_actual.values, y_preds.values, labels=(0,1))\n",
    "print(colored(f'MODEL VLOSS: {model_loss}', 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa1bb730ddeebc089519bcd4ec0e31841e14f65d7c169a2b301ba6e4e1462a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nasamars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
