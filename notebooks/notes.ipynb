{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_parms = { \n",
    "    'max_depth':2, \n",
    "    'learning_rate':0.01, \n",
    "    'subsample':0.4,\n",
    "    'colsample_bytree':0.3, \n",
    "    'eval_metric':'logloss',\n",
    "    'objective':'binary:logistic',\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor':'gpu_predictor',\n",
    "    'random_state':42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Add feature importance see Chris' notebook\n",
    "# https://www.kaggle.com/cdeotte/rapids-xgb-fil-silver-medal-train-0-804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier( \n",
    "        n_estimators=2000,\n",
    "        max_depth=12, \n",
    "        learning_rate=0.02, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.4, \n",
    "        missing=-1, \n",
    "        eval_metric='auc',\n",
    "        # USE CPU\n",
    "        #nthread=4,\n",
    "        #tree_method='hist' \n",
    "        # USE GPU\n",
    "        tree_method='gpu_hist' \n",
    "    )\n",
    "    h = clf.fit(X_train.loc[idxT,cols], y_train[idxT], \n",
    "        eval_set=[(X_train.loc[idxV,cols],y_train[idxV])],\n",
    "        verbose=50, early_stopping_rounds=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
