{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment\n",
    "# Change main system path to be able to run code from src folder\n",
    "import sys\n",
    "p = sys.path[0]\n",
    "# Mac OS\n",
    "if sys.path[0].endswith('/models'):\n",
    "    main_path = p[:-len('/models')]\n",
    "sys.path[0] = main_path\n",
    "\n",
    "import os, gc, json \n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from src import (config, fe, features, feature_selection, \n",
    "                 preprocess, training)\n",
    "from src.fe import CreateFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (1570, 5)\n",
      "Train labels: (766, 11)\n",
      "Train labels: (293, 11)\n",
      "Submission: (804, 11)\n",
      "['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n",
      "Labels w/o SAM : (1047, 11)\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "# ===== LOAD DATA ======\n",
    "metadata = pd.read_csv(config.DATA_DIR + 'metadata.csv')\n",
    "print(f'Metadata: {metadata.shape}')\n",
    "\n",
    "train_labels = pd.read_csv(config.DATA_DIR + 'train_labels.csv')\n",
    "print(f'Train labels: {train_labels.shape}')\n",
    "\n",
    "valid_labels = pd.read_csv(config.DATA_DIR + 'val_labels.csv')\n",
    "print(f'Train labels: {valid_labels.shape}')\n",
    "\n",
    "# Combine train and valid labels\n",
    "trvl_labels = pd.concat([train_labels, valid_labels], axis = 0)\n",
    "\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "print(f'Submission: {submission.shape}')\n",
    "\n",
    "# ===== FILE PATHS OF SAMPLES =====\n",
    "train_files = metadata[metadata.split == 'train']['features_path'].to_dict()\n",
    "valid_files = metadata[metadata.split == 'val']['features_path'].to_dict()\n",
    "test_files = metadata[metadata.split == 'test']['features_path'].to_dict()\n",
    "# Train & Valid files\n",
    "trva_files = train_files.copy()\n",
    "trva_files.update(valid_files)\n",
    "# All files\n",
    "all_test_files = valid_files.copy()\n",
    "all_test_files.update(test_files)\n",
    "\n",
    "# Define SAM testbed files\n",
    "sam_files = metadata[(metadata.instrument_type == 'sam_testbed') & (metadata.split == 'train')]['features_path']\n",
    "sam_files = sam_files.to_dict()\n",
    "\n",
    "# Get the names of the target columns in a list\n",
    "target_labels_list = [i for i in train_labels.columns if i not in ['sample_id']]\n",
    "print(target_labels_list)\n",
    "\n",
    "# SAM testbed labels\n",
    "sam_labels = train_labels.drop(train_labels.tail(len(sam_files)).index)\n",
    "sam_labels = pd.concat([sam_labels, valid_labels], axis=0)\n",
    "print(f'Labels w/o SAM : {sam_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'basalt'\n",
    "# Base model features\n",
    "INITIAL_FTS = 'fts_mra_tempmz'\n",
    "# Features to add to the base model\n",
    "ALL_FTS_GROUPS = config.FTS_GROUPS\n",
    "MODEL_ALGO = 'XGB_opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TYPE = 'tr'\n",
    "\n",
    "# Save best model features: CV loss the lowest when compared to previous fitted model\n",
    "BEST_MODEL_FTS_GROUPS = [INITIAL_FTS]   # Name of a feature group included in the final model\n",
    "BEST_MODEL_FTS = []                     # Selected features after SFM if applied\n",
    "BEST_MODEL_CVLOSS = 0\n",
    "BEST_MODEL_VLOSS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INITIAL TRAINING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train initial: (766, 1584)\n",
      "Reading features: \u001b[33mfts_mra_tempmz_XGB_opt_tr_SFM_COLS.txt\u001b[0m\n",
      "No features added: \u001b[34m31\u001b[0m\n",
      "\u001b[32mX_train base: (766, 31)\u001b[0m\n",
      "\u001b[32mX_vlte base: (804, 31)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Inital X_train: base model features\n",
    "X_train = pd.read_csv(os.path.join(config.DATA_DIR_OUT, \n",
    "                                   INITIAL_FTS + '_' + SPLIT_TYPE + '.csv'))\n",
    "print(f'X_train initial: {X_train.shape}')\n",
    "initial_fts_path = INITIAL_FTS + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_SFM_COLS.txt'\n",
    "if os.path.exists(initial_fts_path):\n",
    "    print(f'Reading features:', colored(f'{initial_fts_path}', 'yellow'))\n",
    "    with open(initial_fts_path) as json_file:\n",
    "            initial_fts_dict = json.load(json_file)\n",
    "    BEST_MODEL_FTS = BEST_MODEL_FTS + initial_fts_dict[LABEL]\n",
    "    print(f'No features added:',colored(f'{len(initial_fts_dict[LABEL])}', 'blue'))\n",
    "else:\n",
    "    BEST_MODEL_FTS = BEST_MODEL_FTS + X_train.columns.tolist()\n",
    "    print(f'No features added:',colored(f'{len(X_train.columns.tolist())}', 'blue'))\n",
    "\n",
    "# Redefine X_train given new set of features\n",
    "X_train = X_train[BEST_MODEL_FTS].copy()\n",
    "print(colored(f'X_train base: {X_train.shape}', 'green'))\n",
    "\n",
    "# Define validation & test dataset\n",
    "X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, \n",
    "                                  INITIAL_FTS + '_vlte.csv'))\n",
    "X_vlte = X_vlte[BEST_MODEL_FTS].copy()\n",
    "print(colored(f'X_vlte base: {X_vlte.shape}', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base features: ['fts_mra_tempmz']\n",
      "Feature group: \u001b[33mfts_topmz\u001b[0m\n",
      "Reading features: fts_mra_tempmz_XGB_opt_tr_SFM_COLS.txt\n",
      "X_train: (766, 1587)\n",
      "\n",
      "Base features: ['fts_mra_tempmz']\n",
      "Feature group: \u001b[33mfts_slope_tt\u001b[0m\n",
      "Reading features: fts_mra_tempmz_XGB_opt_tr_SFM_COLS.txt\n",
      "X_train: (766, 1585)\n"
     ]
    }
   ],
   "source": [
    "for FTS_GROUP in ALL_FTS_GROUPS[:2]:\n",
    "    print(f'\\nBase features: {BEST_MODEL_FTS_GROUPS}')\n",
    "    print(f'Feature group:', colored(f'{FTS_GROUP}', 'yellow'))\n",
    "\n",
    "    # ===== DATASET =====\n",
    "    X_train = pd.DataFrame()\n",
    "    \n",
    "    # If the feature is not already included in the best model\n",
    "    if FTS_GROUP not in BEST_MODEL_FTS_GROUPS:\n",
    "        # Combine BEST_MODEL_FTS_GROUPS and FTS_GROUP\n",
    "        for fg in BEST_MODEL_FTS_GROUPS:\n",
    "            df_fg = pd.read_csv(os.path.join(config.DATA_DIR_OUT, fg + '_' + SPLIT_TYPE + '.csv'))\n",
    "            X_train = pd.concat([X_train, df_fg], axis=1)\n",
    "\n",
    "            # Get columns\n",
    "            df_fg_cols_path = fg + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_SFM_COLS.txt'     \n",
    "            if os.path.exists(df_fg_cols_path):\n",
    "                print(f'Reading features: {df_fg_cols_path}')\n",
    "                with open(df_fg_cols_path) as json_file:\n",
    "                        fg_fts_dict = json.load(json_file)\n",
    "                BEST_MODEL_FTS.append(fg_fts_dict[LABEL])\n",
    "            else:\n",
    "                print(f'Appending features: {df_fg_cols_path}')\n",
    "                BEST_MODEL_FTS = BEST_MODEL_FTS + df_fg.columns.tolist()\n",
    "            \n",
    "        # Add current feature group\n",
    "        df_cf = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_GROUP + '_' + SPLIT_TYPE + '.csv'))\n",
    "        X_train = pd.concat([X_train, df_cf], axis=1)\n",
    "        print(f'X_train: {X_train.shape}')\n",
    "\n",
    "        # Combine BEST_MODEL_FTS and FTS_GROUP columns\n",
    "        \n",
    "        \n",
    "        # Train & compare logloss\n",
    "        \n",
    "        # Record stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEST_MODEL_FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTS_NAME = 'fts_mra_tempmz_maxabun'                 # Name of the file with base features for TRAINING\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "COMPUTE_FTS_SAM = False                                 # Compute SAM test bed\n",
    "MODEL_ALGO = 'XGB_opt'                                  # Name of the classifier\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO                # Name of the model\n",
    "COMBINE_FTS = ['fts_mra_tempmz', 'fts_mz_maxabun']   # Feature sets to combine for training\n",
    "NEW_FEATURES = None                                        # Name of a data frame with new features to add to model\n",
    "TRAIN_FTS_SFM = ['fts_mra_tempmz', 'fts_mz_maxabun'] # Features selected with SMF() for training.   \n",
    "BASE_MODEL_FTS = 'fts_mra_tempmz'\n",
    "BASE_MODEL = BASE_MODEL_FTS + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPUTE FEATURES**\n",
    "\n",
    "- Change the `fe._` method depending on the feature that we wish to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1683)\u001b[0m\n",
      "\u001b[34mtrain & valid => (1059, 1683)\u001b[0m\n",
      "\u001b[34mvalid & test => (804, 1683)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train & valid => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'valid & test => {X_vlte.shape}', 'blue'))\n",
    "    \n",
    "if COMPUTE_FTS_SAM:\n",
    "    print(f'\\nCreating SAM testbed samples ...')\n",
    "    # Training without SAM testbed\n",
    "    X_tr_sam = X_tr.drop(X_tr.tail(len(sam_files)).index).copy()\n",
    "    X_tr_sam = pd.concat([X_tr_sam, X_trvl.iloc[len(train_files):,:]], axis=0)\n",
    "    print(f'Train shape: {X_tr_sam.shape}')\n",
    "    # Validation data\n",
    "    X_vl_sam = X_tr.tail(len(sam_files)).copy()\n",
    "    print(f'Valid shape: {X_vl_sam.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fts_mra_tempmz\n",
      "Adding fts_mz_maxabun\n",
      "Saving fts_mra_tempmz_maxabun_XGB_opt_tr_SFM_COLS.txt\n"
     ]
    }
   ],
   "source": [
    "split_type = 'tr'\n",
    "feature_selection.combine_sfm_features(\n",
    "                    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "                    fitted_model_algo=MODEL_ALGO,\n",
    "                    target_labels_list=target_labels_list,\n",
    "                    split_type=split_type,\n",
    "                    fitted_model_name=FTS_NAME)\n",
    "#TRAIN_FTS_SFM = FTS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_maxabun_XGB_opt_tr_SFM_COLS.txt\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_XGB_opt_tr_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.19076\u001b[0m \u001b[32m-> -0.01303\u001b[0m\n",
      "\u001b[33mcarbonate: LogLoss=0.10985\u001b[0m \u001b[31m-> 0.00105\u001b[0m\n",
      "\u001b[33mchloride: LogLoss=0.18517\u001b[0m \u001b[32m-> -0.02477\u001b[0m\n",
      "\u001b[33miron_oxide: LogLoss=0.22697\u001b[0m \u001b[31m-> 0.00276\u001b[0m\n",
      "\u001b[33moxalate: LogLoss=0.02271\u001b[0m \u001b[32m-> -0.00327\u001b[0m\n",
      "\u001b[33moxychlorine: LogLoss=0.1644\u001b[0m \u001b[32m-> -0.01577\u001b[0m\n",
      "\u001b[33mphyllosilicate: LogLoss=0.24467\u001b[0m \u001b[32m-> -0.0007\u001b[0m\n",
      "\u001b[33msilicate: LogLoss=0.24195\u001b[0m \u001b[31m-> 0.00877\u001b[0m\n",
      "\u001b[33msulfate: LogLoss=0.20801\u001b[0m \u001b[31m-> 0.01785\u001b[0m\n",
      "\u001b[33msulfide: LogLoss=0.06749\u001b[0m \u001b[32m-> -4e-05\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 55\u001b[0m\n",
      "\u001b[32mcarbonate - nfeatures: 143\u001b[0m\n",
      "\u001b[32mchloride - nfeatures: 91\u001b[0m\n",
      "\u001b[32miron_oxide - nfeatures: 249\u001b[0m\n",
      "\u001b[32moxalate - nfeatures: 27\u001b[0m\n",
      "\u001b[32moxychlorine - nfeatures: 83\u001b[0m\n",
      "\u001b[32mphyllosilicate - nfeatures: 316\u001b[0m\n",
      "\u001b[32msilicate - nfeatures: 1604\u001b[0m\n",
      "\u001b[32msulfate - nfeatures: 174\u001b[0m\n",
      "\u001b[32msulfide - nfeatures: 123\u001b[0m\n",
      "Saving fts_mra_tempmz_maxabun_XGB_opt_tr_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.1662\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.15337\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "split_type = 'tr'\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=None,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_tr,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type='tr',\n",
    "    train_labels=train_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=FTS_NAME)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=split_type,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + split_type,\n",
    "    base_model_name=BASE_MODEL_FTS + '_' + MODEL_ALGO + '_' + split_type + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + split_type,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN & VALID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTS_NAME = 'fts_mra_tempmz_maxabun'                 # Name of the file with base features for TRAINING\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "COMPUTE_FTS_SAM = False                                 # Compute SAM test bed\n",
    "MODEL_ALGO = 'XGB_opt'                                  # Name of the classifier\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO                # Name of the model\n",
    "COMBINE_FTS = ['fts_mra_tempmz', 'fts_mz_maxabun']   # Feature sets to combine for training\n",
    "NEW_FEATURES = None                                        # Name of a data frame with new features to add to model\n",
    "TRAIN_FTS_SFM = ['fts_mra_tempmz', 'fts_mz_maxabun'] # Features selected with SMF() for training.   \n",
    "BASE_MODEL_FTS = 'fts_mra_tempmz'\n",
    "BASE_MODEL = BASE_MODEL_FTS + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fts_mra_tempmz\n",
      "Adding fts_mz_maxabun\n",
      "Saving fts_mra_tempmz_maxabun_XGB_opt_trvl_SFM_COLS.txt\n"
     ]
    }
   ],
   "source": [
    "split_type = 'trvl'\n",
    "feature_selection.combine_sfm_features(\n",
    "                    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "                    fitted_model_algo=MODEL_ALGO,\n",
    "                    target_labels_list=target_labels_list,\n",
    "                    split_type=split_type,\n",
    "                    fitted_model_name=FTS_NAME)\n",
    "#TRAIN_FTS_SFM = FTS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_maxabun_XGB_opt_trvl_SFM_COLS.txt\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_XGB_opt_trvl_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.15847\u001b[0m \u001b[32m-> -0.00183\u001b[0m\n",
      "\u001b[33mcarbonate: LogLoss=0.0845\u001b[0m \u001b[32m-> -0.00498\u001b[0m\n",
      "\u001b[33mchloride: LogLoss=0.17325\u001b[0m \u001b[31m-> 0.00225\u001b[0m\n",
      "\u001b[33miron_oxide: LogLoss=0.20251\u001b[0m \u001b[32m-> -0.00854\u001b[0m\n",
      "\u001b[33moxalate: LogLoss=0.01159\u001b[0m \u001b[32m-> -0.00251\u001b[0m\n",
      "\u001b[33moxychlorine: LogLoss=0.15008\u001b[0m \u001b[32m-> -0.00967\u001b[0m\n",
      "\u001b[33mphyllosilicate: LogLoss=0.2372\u001b[0m \u001b[32m-> -0.0021\u001b[0m\n",
      "\u001b[33msilicate: LogLoss=0.18702\u001b[0m \u001b[31m-> 0.00028\u001b[0m\n",
      "\u001b[33msulfate: LogLoss=0.16424\u001b[0m \u001b[32m-> -0.00932\u001b[0m\n",
      "\u001b[33msulfide: LogLoss=0.0811\u001b[0m \u001b[32m-> -0.00057\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 1646\u001b[0m\n",
      "\u001b[32mcarbonate - nfeatures: 287\u001b[0m\n",
      "\u001b[32mchloride - nfeatures: 1667\u001b[0m\n",
      "\u001b[32miron_oxide - nfeatures: 1678\u001b[0m\n",
      "\u001b[32moxalate - nfeatures: 34\u001b[0m\n",
      "\u001b[32moxychlorine - nfeatures: 1676\u001b[0m\n",
      "\u001b[32mphyllosilicate - nfeatures: 1672\u001b[0m\n",
      "\u001b[32msilicate - nfeatures: 1683\u001b[0m\n",
      "\u001b[32msulfate - nfeatures: 1670\u001b[0m\n",
      "\u001b[32msulfide - nfeatures: 1683\u001b[0m\n",
      "Saving fts_mra_tempmz_maxabun_XGB_opt_trvl_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.14499\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.01087\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "split_type = 'trvl'\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=None,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_trvl,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type=split_type,\n",
    "    train_labels=trvl_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=FTS_NAME)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_trvl,\n",
    "    df_labels=trvl_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=split_type,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + split_type,\n",
    "    base_model_name=BASE_MODEL_FTS + '_' + MODEL_ALGO + '_' + split_type + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + split_type,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAM TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa1bb730ddeebc089519bcd4ec0e31841e14f65d7c169a2b301ba6e4e1462a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nasamars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
