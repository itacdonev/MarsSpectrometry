{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "## Environment\n",
    "# Change main system path to be able to run code from src folder\n",
    "import sys\n",
    "p = sys.path[0]\n",
    "# Mac OS\n",
    "if sys.path[0].endswith('/models'):\n",
    "    main_path = p[:-len('/models')]\n",
    "sys.path[0] = main_path\n",
    "\n",
    "import os, gc, json\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from src import (config, fe, features, feature_selection, \n",
    "                 preprocess, training)\n",
    "from src.fe import CreateFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (1570, 5)\n",
      "Train labels: (766, 11)\n",
      "Train labels: (293, 11)\n",
      "Submission: (804, 11)\n",
      "['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n",
      "Labels w/o SAM : (1047, 11)\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "# ===== LOAD DATA ======\n",
    "metadata = pd.read_csv(config.DATA_DIR + 'metadata.csv')\n",
    "print(f'Metadata: {metadata.shape}')\n",
    "\n",
    "train_labels = pd.read_csv(config.DATA_DIR + 'train_labels.csv')\n",
    "print(f'Train labels: {train_labels.shape}')\n",
    "\n",
    "valid_labels = pd.read_csv(config.DATA_DIR + 'val_labels.csv')\n",
    "print(f'Train labels: {valid_labels.shape}')\n",
    "\n",
    "# Combine train and valid labels\n",
    "trvl_labels = pd.concat([train_labels, valid_labels], axis = 0)\n",
    "\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "print(f'Submission: {submission.shape}')\n",
    "\n",
    "# ===== FILE PATHS OF SAMPLES =====\n",
    "train_files = metadata[metadata.split == 'train']['features_path'].to_dict()\n",
    "valid_files = metadata[metadata.split == 'val']['features_path'].to_dict()\n",
    "test_files = metadata[metadata.split == 'test']['features_path'].to_dict()\n",
    "# Train & Valid files\n",
    "trva_files = train_files.copy()\n",
    "trva_files.update(valid_files)\n",
    "# All files\n",
    "all_test_files = valid_files.copy()\n",
    "all_test_files.update(test_files)\n",
    "\n",
    "# Define SAM testbed files\n",
    "sam_files = metadata[(metadata.instrument_type == 'sam_testbed') & (metadata.split == 'train')]['features_path']\n",
    "sam_files = sam_files.to_dict()\n",
    "\n",
    "# Get the names of the target columns in a list\n",
    "target_labels_list = [i for i in train_labels.columns if i not in ['sample_id']]\n",
    "print(target_labels_list)\n",
    "\n",
    "# SAM testbed labels\n",
    "sam_labels = train_labels.drop(train_labels.tail(len(sam_files)).index)\n",
    "sam_labels = pd.concat([sam_labels, valid_labels], axis=0)\n",
    "print(f'Labels w/o SAM : {sam_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base + Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of all feature groups\n",
    "FTS_GROUPS = config.FTS_GROUPS\n",
    "LABEL = 'basalt'\n",
    "target_labels_list = [LABEL]\n",
    "SPLIT_TYPE = 'tr'\n",
    "MODEL_ALGO = 'XGB_opt'                                  # Name of the classifier\n",
    "\n",
    "path_base_fts = os.path.join(config.MODELS_DIR, \n",
    "                         'models_base_label.txt')\n",
    "with open(path_base_fts) as json_file:\n",
    "    base_features = json.load(json_file)\n",
    "BASE_MODEL_FTS = base_features[LABEL]\n",
    "BASE_MODEL_FTS = BASE_MODEL_FTS.split('_'+MODEL_ALGO)[0]\n",
    "\n",
    "FTS_NAME = 'fts_mra_tempmz_slope'                       # Name of the file with base features for TRAINING\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO + '_' + LABEL                # Name of the model\n",
    "NEW_FEATURES = 'fts_slope_tt'                           # Name of a data frame with new features to add to model\n",
    "COMBINE_FTS = [BASE_MODEL_FTS, NEW_FEATURES]        # Feature sets to combine for training\n",
    "TRAIN_FTS_SFM = BASE_MODEL_FTS                        # Features selected with SMF() for training.\n",
    "BASE_MODEL = TRAIN_FTS_SFM + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1585)\u001b[0m\n",
      "\u001b[34mtrain & valid => (1059, 1585)\u001b[0m\n",
      "\u001b[34mvalid & test => (804, 1585)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train & valid => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'valid & test => {X_vlte.shape}', 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_XGB_opt_tr_SFM_COLS.txt\n",
      "Adding features from fts_slope_tt\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_XGB_opt_tr_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.19118\u001b[0m \u001b[32m-> -0.01261\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 32\u001b[0m\n",
      "Saving fts_mra_tempmz_slope_XGB_opt_basalt_tr_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.19118\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.12257\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=BASE_MODEL,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_tr,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    train_labels=train_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=TRAIN_FTS_SFM)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "    base_model_name=TRAIN_FTS_SFM + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `lr_corr_mz4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_FTS = 'fts_mra_tempmz_slope'\n",
    "NEW_FEATURES = 'fts_lr_corr_mz4'                           # Name of a data frame with new features to add to model\n",
    "FTS_NAME = 'fts_mra_tempmz_slope_lrcorrmz4'                       # Name of the file with base features for TRAINING\n",
    "\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO                # Name of the model\n",
    "COMBINE_FTS = [BASE_MODEL_FTS, NEW_FEATURES]        # Feature sets to combine for training\n",
    "TRAIN_FTS_SFM = BASE_MODEL_FTS                        # Features selected with SMF() for training.\n",
    "BASE_MODEL = TRAIN_FTS_SFM + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1586)\u001b[0m\n",
      "\u001b[34mtrain & valid => (1059, 1586)\u001b[0m\n",
      "\u001b[34mvalid & test => (804, 1586)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train & valid => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'valid & test => {X_vlte.shape}', 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_slope_XGB_opt_tr_SFM_COLS.txt\n",
      "Adding features from fts_lr_corr_mz4\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_slope_XGB_opt_tr_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.19294\u001b[0m \u001b[31m-> 0.00177\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 33\u001b[0m\n",
      "Saving fts_mra_tempmz_slope_lrcorrmz4_XGB_opt_tr_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.19294\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.13273\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=BASE_MODEL,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_tr,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    train_labels=train_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=TRAIN_FTS_SFM)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "    base_model_name=TRAIN_FTS_SFM + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `fts_cntpk_mratt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_FTS = 'fts_mra_tempmz_slope'\n",
    "NEW_FEATURES = 'fts_cntpk_mratt'                           # Name of a data frame with new features to add to model\n",
    "FTS_NAME = 'fts_mra_tempmz_slope_cntpk'                       # Name of the file with base features for TRAINING\n",
    "\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO                # Name of the model\n",
    "COMBINE_FTS = [BASE_MODEL_FTS, NEW_FEATURES]        # Feature sets to combine for training\n",
    "TRAIN_FTS_SFM = BASE_MODEL_FTS                        # Features selected with SMF() for training.\n",
    "BASE_MODEL = TRAIN_FTS_SFM + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1981)\u001b[0m\n",
      "\u001b[34mtrain & valid => (1059, 1981)\u001b[0m\n",
      "\u001b[34mvalid & test => (804, 1981)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train & valid => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'valid & test => {X_vlte.shape}', 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_slope_XGB_opt_tr_SFM_COLS.txt\n",
      "Adding features from fts_cntpk_mratt\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_slope_XGB_opt_tr_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.18535\u001b[0m \u001b[32m-> -0.00583\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 428\u001b[0m\n",
      "Saving fts_mra_tempmz_slope_cntpk_XGB_opt_tr_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.18535\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.12594\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=BASE_MODEL,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_tr,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    train_labels=train_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=TRAIN_FTS_SFM)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "    base_model_name=TRAIN_FTS_SFM + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `fts_topmz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_FTS = 'fts_mra_tempmz_slope_cntpk'\n",
    "NEW_FEATURES = 'fts_topmz'                           # Name of a data frame with new features to add to model\n",
    "FTS_NAME = 'fts_mra_tempmz_slope_cntpk_topmz'                       # Name of the file with base features for TRAINING\n",
    "\n",
    "COMPUTE_FTS = True                                      # Should the features be recomputed\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO                # Name of the model\n",
    "COMBINE_FTS = [BASE_MODEL_FTS, NEW_FEATURES]        # Feature sets to combine for training\n",
    "TRAIN_FTS_SFM = BASE_MODEL_FTS                        # Features selected with SMF() for training.\n",
    "BASE_MODEL = TRAIN_FTS_SFM + '_' + MODEL_ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1984)\u001b[0m\n",
      "\u001b[34mtrain & valid => (1059, 1984)\u001b[0m\n",
      "\u001b[34mvalid & test => (804, 1984)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train & valid => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'valid & test => {X_vlte.shape}', 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading feature column names\u001b[0m\n",
      "Reading fts_mra_tempmz_slope_cntpk_XGB_opt_tr_SFM_COLS.txt\n",
      "Adding features from fts_topmz\n",
      "\u001b[34mCV training ....\u001b[0m\n",
      "Basel model CVloss: ../models/fts_mra_tempmz_slope_cntpk_XGB_opt_tr_sfm_cvloss.csv\n",
      "\u001b[33mbasalt: LogLoss=0.17807\u001b[0m \u001b[32m-> -0.00727\u001b[0m\n",
      "\u001b[34mFull training .....\u001b[0m\n",
      "\u001b[32mbasalt - nfeatures: 79\u001b[0m\n",
      "Saving fts_mra_tempmz_slope_cntpk_topmz_XGB_opt_tr_COLS_sfm.txt\n",
      "\u001b[33mCV LogLoss: 0.17807\u001b[0m\n",
      "\u001b[32mVAL LogLoss: 0.12618\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "\n",
    "# Initialize the feature selection class\n",
    "smf = feature_selection.SelectModelFeatures(\n",
    "    base_sfm_features_name=TRAIN_FTS_SFM,\n",
    "    base_fitted_model_name=BASE_MODEL,\n",
    "    target_labels_list=target_labels_list,\n",
    "    new_features_file_name=NEW_FEATURES,\n",
    "    fitted_model_name=MODEL_NAME,\n",
    "    fitted_model_algo=MODEL_ALGO,\n",
    "    X_tr=X_tr,\n",
    "    X_vlte=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    train_labels=train_labels,\n",
    "    valid_files=valid_files,\n",
    "    valid_labels=valid_labels)\n",
    "\n",
    "if TRAIN_FTS_SFM:\n",
    "    # Loads FTS_NAME_tr_SFM_COLS - cols to train with if\n",
    "    # training is done without full column lenght of input data\n",
    "    TRAIN_FTS_DICT = smf.load_features(file_name=TRAIN_FTS_SFM)\n",
    "else: \n",
    "    TRAIN_FTS_DICT = None\n",
    "\n",
    "# Train the model- saves features as MODEL_NAME_tr_COLS.txt'\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    split_type=SPLIT_TYPE,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "    base_model_name=TRAIN_FTS_SFM + '_' + MODEL_ALGO + '_' + SPLIT_TYPE + '_sfm',\n",
    "    fts_select_cols=TRAIN_FTS_DICT,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_' + SPLIT_TYPE,\n",
    "                                               fts_select_cols=TRAIN_FTS_DICT)\n",
    "print(colored(f'VAL LogLoss: {np.round(mloss_avg, 5)}', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa1bb730ddeebc089519bcd4ec0e31841e14f65d7c169a2b301ba6e4e1462a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nasamars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
