{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL TRAINING NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change main system path to be able to run code from src folder\n",
    "import sys\n",
    "p = sys.path[0]\n",
    "# Mac OS\n",
    "if sys.path[0].endswith('/notebooks'):\n",
    "    main_path = p[:-len('/notebooks')]\n",
    "if sys.path[0].endswith('/techdoc/content'):\n",
    "    main_path = p[:-len('/techdoc/content')]\n",
    "    \n",
    "# Windows OS\n",
    "if sys.path[0].endswith('\\\\notebooks'): \n",
    "    main_path = p[:-len('\\\\notebooks')]\n",
    "if sys.path[0].endswith('\\\\techdoc\\content'): \n",
    "    main_path = p[:-len('\\\\techdoc\\content')]\n",
    "\n",
    "sys.path[0] = main_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import gc, itertools\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from src import (config, describe_data, features,\n",
    "                 preprocess, training, utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (1570, 5)\n",
      "Train labels: (766, 11)\n",
      "Train labels: (293, 11)\n",
      "Submission: (804, 11)\n"
     ]
    }
   ],
   "source": [
    "# ===== LOAD DATA ======\n",
    "metadata = pd.read_csv(config.DATA_DIR + 'metadata.csv')\n",
    "print(f'Metadata: {metadata.shape}')\n",
    "\n",
    "train_labels = pd.read_csv(config.DATA_DIR + 'train_labels.csv')\n",
    "print(f'Train labels: {train_labels.shape}')\n",
    "\n",
    "valid_labels = pd.read_csv(config.DATA_DIR + 'val_labels.csv')\n",
    "print(f'Train labels: {valid_labels.shape}')\n",
    "\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "print(f'Submission: {submission.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: (766, 5)\n",
      "VALID: (293, 5)\n",
      "TEST: (511, 5)\n"
     ]
    }
   ],
   "source": [
    "# ===== MODEL SAMPLES ======\n",
    "train = metadata[metadata.split == 'train'].copy().reset_index(drop=True)\n",
    "print(f'TRAIN: {train.shape}')\n",
    "\n",
    "valid = metadata[metadata.split == 'val'].copy().reset_index(drop=True)\n",
    "print(f'VALID: {valid.shape}')\n",
    "\n",
    "test = metadata[metadata.split == 'test'].copy().reset_index(drop=True)\n",
    "print(f'TEST: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n"
     ]
    }
   ],
   "source": [
    "# ===== FILE PATHS OF SAMPLES =====\n",
    "train_files = metadata[metadata.split == 'train']['features_path'].to_dict()\n",
    "valid_files = metadata[metadata.split == 'val']['features_path'].to_dict()\n",
    "test_files = metadata[metadata.split == 'test']['features_path'].to_dict()\n",
    "# Train & Valid files\n",
    "trva_files = train_files.copy()\n",
    "trva_files.update(valid_files)\n",
    "# All files\n",
    "all_test_files = valid_files.copy()\n",
    "all_test_files.update(test_files)\n",
    "\n",
    "# Ion type list\n",
    "ion_list = list(np.arange(0,100,1.0))\n",
    "\n",
    "# Get the names of the target columns in a list\n",
    "target_labels_list = [i for i in train_labels.columns if i not in ['sample_id']]\n",
    "print(target_labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING PREPPROCESSING\n",
    "\n",
    "We need to create a 3D array, where the 1st dimension are samples, 2nd dimension are features and the 3rd dimension are the time steps. Since the raw time steps repeat given a different ion type, i.e. `m/z` we need to construct features with respect to the ion type. So we will have `1.0_temp`, `1.0_abundance`, `2.0_temp`, `2.0_abundance`, etc. Furthermore, the time is measured in seconds and time steps are not uniform and even across samples. Different time measurements are across samples. Hence, we will first compute the maximum time present in the training, validation and test samples and then aggregate all the data in 10 second time intervals. This will provide a full data array instead of a sparse one. Also it will significantly reduce the training size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1570/1570 [01:53<00:00, 13.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5248.14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE MAXIMUM TIME ACROSS ALL SAMPLES\n",
    "max_time = preprocess.compute_max_time_samples(metadata)\n",
    "max_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are the time steps and `m/z` values unique?** We need only one row per sample given one time step. Hence, we need to ensure that the time steps and the ion types are unique. We should add this check (that one row is being created for one sample and one time period) when we construct the final array.\n",
    "\n",
    "In the `sam_testbed` samples, there are differences in temperature per `time_bin` and the ion type, where per one `temp_bin`we get different temperature values per diferent ion type. This leads to duplicates in the rows per time step. See sample 765 for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "ht['check'] = ht.groupby(['time', 'm/z'])['time'].transform('count')\n",
    "ht[ht['check'] > 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [05:48<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402150, 104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_osc_time</th>\n",
       "      <th>mz_0_abund</th>\n",
       "      <th>mz_1_abund</th>\n",
       "      <th>mz_2_abund</th>\n",
       "      <th>mz_3_abund</th>\n",
       "      <th>mz_5_abund</th>\n",
       "      <th>mz_6_abund</th>\n",
       "      <th>mz_7_abund</th>\n",
       "      <th>...</th>\n",
       "      <th>mz_92_abund</th>\n",
       "      <th>mz_93_abund</th>\n",
       "      <th>mz_94_abund</th>\n",
       "      <th>mz_95_abund</th>\n",
       "      <th>mz_96_abund</th>\n",
       "      <th>mz_97_abund</th>\n",
       "      <th>mz_98_abund</th>\n",
       "      <th>mz_99_abund</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.914604e-06</td>\n",
       "      <td>1.719285e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.339071e-06</td>\n",
       "      <td>9.866536e-07</td>\n",
       "      <td>1.572230e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.738569e-07</td>\n",
       "      <td>2.132724e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.0, 20.0)</td>\n",
       "      <td>35.420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.390866e-06</td>\n",
       "      <td>1.932152e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.459132e-06</td>\n",
       "      <td>2.169595e-06</td>\n",
       "      <td>2.155304e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.218669e-06</td>\n",
       "      <td>2.416544e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20.0, 30.0)</td>\n",
       "      <td>35.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8.339909e-07</td>\n",
       "      <td>1.657618e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.039618e-06</td>\n",
       "      <td>1.211452e-06</td>\n",
       "      <td>5.682833e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.589236e-06</td>\n",
       "      <td>9.542845e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30.0, 40.0)</td>\n",
       "      <td>36.329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.631496e-06</td>\n",
       "      <td>5.990105e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.548532e-07</td>\n",
       "      <td>3.817495e-06</td>\n",
       "      <td>1.514565e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.403524e-06</td>\n",
       "      <td>9.485680e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40.0, 50.0)</td>\n",
       "      <td>37.293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.161267e-06</td>\n",
       "      <td>1.754442e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.333112e-07</td>\n",
       "      <td>2.654991e-06</td>\n",
       "      <td>2.064771e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.821823e-06</td>\n",
       "      <td>1.904639e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>commercial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_bin    temp  temp_osc_time  mz_0_abund  mz_1_abund  mz_2_abund  \\\n",
       "0   [0.0, 10.0)  35.289            0.0    0.000172    0.000151    0.000045   \n",
       "1  [10.0, 20.0)  35.420            0.0    0.000182    0.000163    0.000042   \n",
       "2  [20.0, 30.0)  35.680            0.0    0.000158    0.000112    0.000038   \n",
       "3  [30.0, 40.0)  36.329            0.0    0.000184    0.000113    0.000031   \n",
       "4  [40.0, 50.0)  37.293            0.0    0.000170    0.000136    0.000062   \n",
       "\n",
       "   mz_3_abund  mz_5_abund    mz_6_abund    mz_7_abund  ...  mz_92_abund  \\\n",
       "0    0.000126    0.000011  1.914604e-06  1.719285e-06  ...     0.000002   \n",
       "1    0.000125    0.000007  3.390866e-06  1.932152e-06  ...     0.000001   \n",
       "2    0.000186    0.000007  8.339909e-07  1.657618e-06  ...     0.000002   \n",
       "3    0.000170    0.000004  1.631496e-06  5.990105e-07  ...     0.000000   \n",
       "4    0.000192    0.000005  2.161267e-06  1.754442e-06  ...     0.000002   \n",
       "\n",
       "    mz_93_abund   mz_94_abund   mz_95_abund  mz_96_abund  mz_97_abund  \\\n",
       "0  1.339071e-06  9.866536e-07  1.572230e-06     0.000002     0.000003   \n",
       "1  2.459132e-06  2.169595e-06  2.155304e-06     0.000002     0.000002   \n",
       "2  2.039618e-06  1.211452e-06  5.682833e-07     0.000002     0.000002   \n",
       "3  7.548532e-07  3.817495e-06  1.514565e-06     0.000002     0.000002   \n",
       "4  8.333112e-07  2.654991e-06  2.064771e-06     0.000002     0.000002   \n",
       "\n",
       "    mz_98_abund   mz_99_abund  sample_id  instrument_type  \n",
       "0  5.738569e-07  2.132724e-06      S0000       commercial  \n",
       "1  1.218669e-06  2.416544e-06      S0000       commercial  \n",
       "2  1.589236e-06  9.542845e-07      S0000       commercial  \n",
       "3  1.403524e-06  9.485680e-07      S0000       commercial  \n",
       "4  1.821823e-06  1.904639e-06      S0000       commercial  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== CREATE TS DF - TRAIN =====\n",
    "df_meta = metadata[metadata.split == 'train']\n",
    "fts_dl_ts = features.dl_ts(df_meta, max_time)\n",
    "print(fts_dl_ts.shape)\n",
    "fts_dl_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to label encode all the non numeric features since the neural network handles only numeric values. In the code below we check which features are not numeric and encode them. Note that the `time_bin` and `sample_id` are not features so no need to encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non numeric features: ['time_bin', 'sample_id', 'instrument_type']\n"
     ]
    }
   ],
   "source": [
    "# ===== ENCODE NON NUMERIC FEATURES =====\n",
    "print(f'Non numeric features: {[i for i in fts_dl_ts if fts_dl_ts[i].dtype not in [\"int\", \"float\"]]}')\n",
    "#print(fts_dl_ts['instrument_type'].value_counts())\n",
    "fts_dl_ts['instrument'] = np.where(fts_dl_ts['instrument_type'] == 'commercial', 1, 0)\n",
    "#print(fts_dl_ts['instrument'].value_counts())\n",
    "del fts_dl_ts['instrument_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== NORMALIZE TEMPERATURE =====\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "fts_dl_ts['temp_sc'] = sc.fit_transform(fts_dl_ts['temp'].values.reshape((fts_dl_ts.shape[0], 1)))\n",
    "del fts_dl_ts['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp_osc_time</th>\n",
       "      <th>mz_0_abund</th>\n",
       "      <th>mz_1_abund</th>\n",
       "      <th>mz_2_abund</th>\n",
       "      <th>mz_3_abund</th>\n",
       "      <th>mz_5_abund</th>\n",
       "      <th>mz_6_abund</th>\n",
       "      <th>mz_7_abund</th>\n",
       "      <th>mz_8_abund</th>\n",
       "      <th>...</th>\n",
       "      <th>mz_93_abund</th>\n",
       "      <th>mz_94_abund</th>\n",
       "      <th>mz_95_abund</th>\n",
       "      <th>mz_96_abund</th>\n",
       "      <th>mz_97_abund</th>\n",
       "      <th>mz_98_abund</th>\n",
       "      <th>mz_99_abund</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>temp_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.914604e-06</td>\n",
       "      <td>1.719285e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339071e-06</td>\n",
       "      <td>9.866536e-07</td>\n",
       "      <td>1.572230e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.738569e-07</td>\n",
       "      <td>2.132724e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.0, 20.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.390866e-06</td>\n",
       "      <td>1.932152e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.459132e-06</td>\n",
       "      <td>2.169595e-06</td>\n",
       "      <td>2.155304e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.218669e-06</td>\n",
       "      <td>2.416544e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20.0, 30.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8.339909e-07</td>\n",
       "      <td>1.657618e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039618e-06</td>\n",
       "      <td>1.211452e-06</td>\n",
       "      <td>5.682833e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.589236e-06</td>\n",
       "      <td>9.542845e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30.0, 40.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.631496e-06</td>\n",
       "      <td>5.990105e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>7.548532e-07</td>\n",
       "      <td>3.817495e-06</td>\n",
       "      <td>1.514565e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.403524e-06</td>\n",
       "      <td>9.485680e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40.0, 50.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.161267e-06</td>\n",
       "      <td>1.754442e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333112e-07</td>\n",
       "      <td>2.654991e-06</td>\n",
       "      <td>2.064771e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.821823e-06</td>\n",
       "      <td>1.904639e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>[5200.0, 5210.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>[5210.0, 5220.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>[5220.0, 5230.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>[5230.0, 5240.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>[5240.0, 5250.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402150 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_bin  temp_osc_time  mz_0_abund  mz_1_abund  mz_2_abund  \\\n",
       "0         [0.0, 10.0)            0.0    0.000172    0.000151    0.000045   \n",
       "1        [10.0, 20.0)            0.0    0.000182    0.000163    0.000042   \n",
       "2        [20.0, 30.0)            0.0    0.000158    0.000112    0.000038   \n",
       "3        [30.0, 40.0)            0.0    0.000184    0.000113    0.000031   \n",
       "4        [40.0, 50.0)            0.0    0.000170    0.000136    0.000062   \n",
       "..                ...            ...         ...         ...         ...   \n",
       "520  [5200.0, 5210.0)            NaN         NaN         NaN         NaN   \n",
       "521  [5210.0, 5220.0)            NaN         NaN         NaN         NaN   \n",
       "522  [5220.0, 5230.0)            NaN         NaN         NaN         NaN   \n",
       "523  [5230.0, 5240.0)            NaN         NaN         NaN         NaN   \n",
       "524  [5240.0, 5250.0)            NaN         NaN         NaN         NaN   \n",
       "\n",
       "     mz_3_abund  mz_5_abund    mz_6_abund    mz_7_abund  mz_8_abund  ...  \\\n",
       "0      0.000126    0.000011  1.914604e-06  1.719285e-06    0.000003  ...   \n",
       "1      0.000125    0.000007  3.390866e-06  1.932152e-06    0.000004  ...   \n",
       "2      0.000186    0.000007  8.339909e-07  1.657618e-06    0.000004  ...   \n",
       "3      0.000170    0.000004  1.631496e-06  5.990105e-07    0.000004  ...   \n",
       "4      0.000192    0.000005  2.161267e-06  1.754442e-06    0.000002  ...   \n",
       "..          ...         ...           ...           ...         ...  ...   \n",
       "520         NaN         NaN           NaN           NaN         NaN  ...   \n",
       "521         NaN         NaN           NaN           NaN         NaN  ...   \n",
       "522         NaN         NaN           NaN           NaN         NaN  ...   \n",
       "523         NaN         NaN           NaN           NaN         NaN  ...   \n",
       "524         NaN         NaN           NaN           NaN         NaN  ...   \n",
       "\n",
       "      mz_93_abund   mz_94_abund   mz_95_abund  mz_96_abund  mz_97_abund  \\\n",
       "0    1.339071e-06  9.866536e-07  1.572230e-06     0.000002     0.000003   \n",
       "1    2.459132e-06  2.169595e-06  2.155304e-06     0.000002     0.000002   \n",
       "2    2.039618e-06  1.211452e-06  5.682833e-07     0.000002     0.000002   \n",
       "3    7.548532e-07  3.817495e-06  1.514565e-06     0.000002     0.000002   \n",
       "4    8.333112e-07  2.654991e-06  2.064771e-06     0.000002     0.000002   \n",
       "..            ...           ...           ...          ...          ...   \n",
       "520           NaN           NaN           NaN          NaN          NaN   \n",
       "521           NaN           NaN           NaN          NaN          NaN   \n",
       "522           NaN           NaN           NaN          NaN          NaN   \n",
       "523           NaN           NaN           NaN          NaN          NaN   \n",
       "524           NaN           NaN           NaN          NaN          NaN   \n",
       "\n",
       "      mz_98_abund   mz_99_abund  sample_id  instrument   temp_sc  \n",
       "0    5.738569e-07  2.132724e-06      S0000           1  0.063589  \n",
       "1    1.218669e-06  2.416544e-06      S0000           1  0.063673  \n",
       "2    1.589236e-06  9.542845e-07      S0000           1  0.063841  \n",
       "3    1.403524e-06  9.485680e-07      S0000           1  0.064261  \n",
       "4    1.821823e-06  1.904639e-06      S0000           1  0.064884  \n",
       "..            ...           ...        ...         ...       ...  \n",
       "520           NaN           NaN      S0765           0       NaN  \n",
       "521           NaN           NaN      S0765           0       NaN  \n",
       "522           NaN           NaN      S0765           0       NaN  \n",
       "523           NaN           NaN      S0765           0       NaN  \n",
       "524           NaN           NaN      S0765           0       NaN  \n",
       "\n",
       "[402150 rows x 104 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_dl_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 102\n"
     ]
    }
   ],
   "source": [
    "# ===== FEATURES LIST =====\n",
    "features_dl = [i for i in fts_dl_ts if i not in ['sample_id', 'time_bin']]\n",
    "print(f'Number of features: {len(features_dl)}')\n",
    "#print(features_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need to replace the NaN values. Since zero is a meaningful value in the sample we will assign a value of -1 to all NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_bin              0\n",
      "temp_osc_time    270491\n",
      "mz_0_abund       283447\n",
      "mz_1_abund       279085\n",
      "mz_2_abund       271886\n",
      "                  ...  \n",
      "mz_98_abund      279730\n",
      "mz_99_abund      279730\n",
      "sample_id             0\n",
      "instrument            0\n",
      "temp_sc          270490\n",
      "Length: 104, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===== FIX NaN VALUES =====\n",
    "print(fts_dl_ts.isnull().sum())\n",
    "fts_dl_ts[features_dl] = fts_dl_ts[features_dl].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp_osc_time</th>\n",
       "      <th>mz_0_abund</th>\n",
       "      <th>mz_1_abund</th>\n",
       "      <th>mz_2_abund</th>\n",
       "      <th>mz_3_abund</th>\n",
       "      <th>mz_5_abund</th>\n",
       "      <th>mz_6_abund</th>\n",
       "      <th>mz_7_abund</th>\n",
       "      <th>mz_8_abund</th>\n",
       "      <th>...</th>\n",
       "      <th>mz_93_abund</th>\n",
       "      <th>mz_94_abund</th>\n",
       "      <th>mz_95_abund</th>\n",
       "      <th>mz_96_abund</th>\n",
       "      <th>mz_97_abund</th>\n",
       "      <th>mz_98_abund</th>\n",
       "      <th>mz_99_abund</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>temp_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.914604e-06</td>\n",
       "      <td>1.719285e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339071e-06</td>\n",
       "      <td>9.866536e-07</td>\n",
       "      <td>1.572230e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.738569e-07</td>\n",
       "      <td>2.132724e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.0, 20.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.390866e-06</td>\n",
       "      <td>1.932152e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.459132e-06</td>\n",
       "      <td>2.169595e-06</td>\n",
       "      <td>2.155304e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.218669e-06</td>\n",
       "      <td>2.416544e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20.0, 30.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8.339909e-07</td>\n",
       "      <td>1.657618e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039618e-06</td>\n",
       "      <td>1.211452e-06</td>\n",
       "      <td>5.682833e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.589236e-06</td>\n",
       "      <td>9.542845e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30.0, 40.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.631496e-06</td>\n",
       "      <td>5.990105e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>7.548532e-07</td>\n",
       "      <td>3.817495e-06</td>\n",
       "      <td>1.514565e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.403524e-06</td>\n",
       "      <td>9.485680e-07</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40.0, 50.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.161267e-06</td>\n",
       "      <td>1.754442e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333112e-07</td>\n",
       "      <td>2.654991e-06</td>\n",
       "      <td>2.064771e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.821823e-06</td>\n",
       "      <td>1.904639e-06</td>\n",
       "      <td>S0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>[5200.0, 5210.0)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>[5210.0, 5220.0)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>[5220.0, 5230.0)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>[5230.0, 5240.0)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>[5240.0, 5250.0)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>S0765</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402150 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_bin  temp_osc_time  mz_0_abund  mz_1_abund  mz_2_abund  \\\n",
       "0         [0.0, 10.0)            0.0    0.000172    0.000151    0.000045   \n",
       "1        [10.0, 20.0)            0.0    0.000182    0.000163    0.000042   \n",
       "2        [20.0, 30.0)            0.0    0.000158    0.000112    0.000038   \n",
       "3        [30.0, 40.0)            0.0    0.000184    0.000113    0.000031   \n",
       "4        [40.0, 50.0)            0.0    0.000170    0.000136    0.000062   \n",
       "..                ...            ...         ...         ...         ...   \n",
       "520  [5200.0, 5210.0)           -1.0   -1.000000   -1.000000   -1.000000   \n",
       "521  [5210.0, 5220.0)           -1.0   -1.000000   -1.000000   -1.000000   \n",
       "522  [5220.0, 5230.0)           -1.0   -1.000000   -1.000000   -1.000000   \n",
       "523  [5230.0, 5240.0)           -1.0   -1.000000   -1.000000   -1.000000   \n",
       "524  [5240.0, 5250.0)           -1.0   -1.000000   -1.000000   -1.000000   \n",
       "\n",
       "     mz_3_abund  mz_5_abund    mz_6_abund    mz_7_abund  mz_8_abund  ...  \\\n",
       "0      0.000126    0.000011  1.914604e-06  1.719285e-06    0.000003  ...   \n",
       "1      0.000125    0.000007  3.390866e-06  1.932152e-06    0.000004  ...   \n",
       "2      0.000186    0.000007  8.339909e-07  1.657618e-06    0.000004  ...   \n",
       "3      0.000170    0.000004  1.631496e-06  5.990105e-07    0.000004  ...   \n",
       "4      0.000192    0.000005  2.161267e-06  1.754442e-06    0.000002  ...   \n",
       "..          ...         ...           ...           ...         ...  ...   \n",
       "520   -1.000000   -1.000000 -1.000000e+00 -1.000000e+00   -1.000000  ...   \n",
       "521   -1.000000   -1.000000 -1.000000e+00 -1.000000e+00   -1.000000  ...   \n",
       "522   -1.000000   -1.000000 -1.000000e+00 -1.000000e+00   -1.000000  ...   \n",
       "523   -1.000000   -1.000000 -1.000000e+00 -1.000000e+00   -1.000000  ...   \n",
       "524   -1.000000   -1.000000 -1.000000e+00 -1.000000e+00   -1.000000  ...   \n",
       "\n",
       "      mz_93_abund   mz_94_abund   mz_95_abund  mz_96_abund  mz_97_abund  \\\n",
       "0    1.339071e-06  9.866536e-07  1.572230e-06     0.000002     0.000003   \n",
       "1    2.459132e-06  2.169595e-06  2.155304e-06     0.000002     0.000002   \n",
       "2    2.039618e-06  1.211452e-06  5.682833e-07     0.000002     0.000002   \n",
       "3    7.548532e-07  3.817495e-06  1.514565e-06     0.000002     0.000002   \n",
       "4    8.333112e-07  2.654991e-06  2.064771e-06     0.000002     0.000002   \n",
       "..            ...           ...           ...          ...          ...   \n",
       "520 -1.000000e+00 -1.000000e+00 -1.000000e+00    -1.000000    -1.000000   \n",
       "521 -1.000000e+00 -1.000000e+00 -1.000000e+00    -1.000000    -1.000000   \n",
       "522 -1.000000e+00 -1.000000e+00 -1.000000e+00    -1.000000    -1.000000   \n",
       "523 -1.000000e+00 -1.000000e+00 -1.000000e+00    -1.000000    -1.000000   \n",
       "524 -1.000000e+00 -1.000000e+00 -1.000000e+00    -1.000000    -1.000000   \n",
       "\n",
       "      mz_98_abund   mz_99_abund  sample_id  instrument   temp_sc  \n",
       "0    5.738569e-07  2.132724e-06      S0000           1  0.063589  \n",
       "1    1.218669e-06  2.416544e-06      S0000           1  0.063673  \n",
       "2    1.589236e-06  9.542845e-07      S0000           1  0.063841  \n",
       "3    1.403524e-06  9.485680e-07      S0000           1  0.064261  \n",
       "4    1.821823e-06  1.904639e-06      S0000           1  0.064884  \n",
       "..            ...           ...        ...         ...       ...  \n",
       "520 -1.000000e+00 -1.000000e+00      S0765           0 -1.000000  \n",
       "521 -1.000000e+00 -1.000000e+00      S0765           0 -1.000000  \n",
       "522 -1.000000e+00 -1.000000e+00      S0765           0 -1.000000  \n",
       "523 -1.000000e+00 -1.000000e+00      S0765           0 -1.000000  \n",
       "524 -1.000000e+00 -1.000000e+00      S0765           0 -1.000000  \n",
       "\n",
       "[402150 rows x 104 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_dl_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that each time bin has all the samples accounted for\n",
    "assert all(fts_dl_ts['time_bin'].value_counts() == fts_dl_ts.sample_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input for the LSTM is a 3D tensor with shape `[batch, timesteps, feature]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 766\n",
      "Time steps: 525\n",
      "Features: 102\n",
      "Data df: (402150, 102)\n",
      "Data reshaped: (766, 525, 102)\n",
      "\n",
      "Labels: ['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n",
      "Labels: (766, 10)\n"
     ]
    }
   ],
   "source": [
    "# ===== CREATE 3D ARRAY (samples, time step, features) =====\n",
    "# ----- Define input layer data -----\n",
    "# Number of samples\n",
    "no_samples = fts_dl_ts.sample_id.nunique()      \n",
    "print(f'Samples: {no_samples}')\n",
    "\n",
    "# Number of time steps\n",
    "no_time_steps = fts_dl_ts.time_bin.nunique()    \n",
    "print(f'Time steps: {no_time_steps}')\n",
    "\n",
    "# Number of features\n",
    "no_features = len(features_dl)                  \n",
    "print(f'Features: {no_features}')\n",
    "\n",
    "# Sort data so that the time steps repeat for each sample_id\n",
    "fts_dl_ts = fts_dl_ts.sort_values(by=['sample_id', 'time_bin'])\n",
    "\n",
    "# Select only features\n",
    "data = fts_dl_ts[features_dl].copy()\n",
    "print(f'Data df: {data.shape}')\n",
    "\n",
    "# Reshape data\n",
    "data = np.array(data)\n",
    "data = data.reshape((no_samples, no_time_steps, no_features))\n",
    "print(f'Data reshaped: {data.shape}')\n",
    "\n",
    "# Prepare labels\n",
    "print(f'\\nLabels: {target_labels_list}')\n",
    "data_y = np.array(train_labels[target_labels_list])\n",
    "data_y = data_y.reshape((no_samples, len(target_labels_list)))\n",
    "print(f'Labels: {data_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model\n",
    "\n",
    "> LSTMs work better with 200-to-400 time steps (J. Brownlee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "FOLD 1\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 08:53:48.594374: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               81200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 295ms/step - loss: 0.4204 - accuracy: 0.8708 - val_loss: 0.3648 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 271ms/step - loss: 0.3769 - accuracy: 0.8810 - val_loss: 0.3687 - val_accuracy: 0.8831\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 9s 311ms/step - loss: 0.3658 - accuracy: 0.8810 - val_loss: 0.3665 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 8s 288ms/step - loss: 0.3699 - accuracy: 0.8810 - val_loss: 0.3608 - val_accuracy: 0.8831\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 305ms/step - loss: 0.3667 - accuracy: 0.8810 - val_loss: 0.3620 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.3708 - accuracy: 0.8810 - val_loss: 0.3612 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 281ms/step - loss: 0.3685 - accuracy: 0.8810 - val_loss: 0.3674 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.3691 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.3669 - accuracy: 0.8810 - val_loss: 0.3621 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.3683 - accuracy: 0.8810 - val_loss: 0.3744 - val_accuracy: 0.8831\n",
      " \n",
      "*************************\n",
      "FOLD 2\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 294ms/step - loss: 0.4159 - accuracy: 0.8737 - val_loss: 0.3617 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.3670 - accuracy: 0.8810 - val_loss: 0.3630 - val_accuracy: 0.8831\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 8s 284ms/step - loss: 0.3678 - accuracy: 0.8810 - val_loss: 0.3697 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.3702 - accuracy: 0.8810 - val_loss: 0.3614 - val_accuracy: 0.8831\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 274ms/step - loss: 0.3666 - accuracy: 0.8810 - val_loss: 0.3642 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 8s 275ms/step - loss: 0.3724 - accuracy: 0.8810 - val_loss: 0.3608 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 302ms/step - loss: 0.3671 - accuracy: 0.8810 - val_loss: 0.3654 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 286ms/step - loss: 0.3682 - accuracy: 0.8810 - val_loss: 0.3637 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 285ms/step - loss: 0.3736 - accuracy: 0.8810 - val_loss: 0.3614 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 0.3707 - accuracy: 0.8810 - val_loss: 0.3635 - val_accuracy: 0.8831\n",
      " \n",
      "*************************\n",
      "FOLD 3\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 11s 320ms/step - loss: 0.4094 - accuracy: 0.8491 - val_loss: 0.3610 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 10s 348ms/step - loss: 0.3733 - accuracy: 0.8810 - val_loss: 0.3841 - val_accuracy: 0.8831\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.3725 - accuracy: 0.8810 - val_loss: 0.3616 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 9s 311ms/step - loss: 0.3739 - accuracy: 0.8810 - val_loss: 0.3617 - val_accuracy: 0.8831\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 287ms/step - loss: 0.3717 - accuracy: 0.8810 - val_loss: 0.3676 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 9s 305ms/step - loss: 0.3748 - accuracy: 0.8810 - val_loss: 0.3926 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 286ms/step - loss: 0.3742 - accuracy: 0.8810 - val_loss: 0.3634 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.3690 - accuracy: 0.8810 - val_loss: 0.3616 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.3672 - accuracy: 0.8810 - val_loss: 0.3624 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 274ms/step - loss: 0.3641 - accuracy: 0.8810 - val_loss: 0.3776 - val_accuracy: 0.8831\n",
      " \n",
      "*************************\n",
      "FOLD 4\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 297ms/step - loss: 0.4278 - accuracy: 0.8607 - val_loss: 0.3640 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.3691 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.3662 - accuracy: 0.8810 - val_loss: 0.3668 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 8s 286ms/step - loss: 0.3800 - accuracy: 0.8810 - val_loss: 0.3625 - val_accuracy: 0.8831\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 284ms/step - loss: 0.3661 - accuracy: 0.8810 - val_loss: 0.3614 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.3707 - accuracy: 0.8810 - val_loss: 0.3662 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.3735 - accuracy: 0.8810 - val_loss: 0.3630 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 275ms/step - loss: 0.3676 - accuracy: 0.8810 - val_loss: 0.3626 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 272ms/step - loss: 0.3668 - accuracy: 0.8810 - val_loss: 0.3608 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 279ms/step - loss: 0.3679 - accuracy: 0.8810 - val_loss: 0.3623 - val_accuracy: 0.8831\n",
      " \n",
      "*************************\n",
      "FOLD 5\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 295ms/step - loss: 0.3930 - accuracy: 0.8810 - val_loss: 0.3637 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.3684 - accuracy: 0.8810 - val_loss: 0.3621 - val_accuracy: 0.8831\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 9s 301ms/step - loss: 0.3726 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 8s 304ms/step - loss: 0.3746 - accuracy: 0.8810 - val_loss: 0.3651 - val_accuracy: 0.8831\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 293ms/step - loss: 0.3692 - accuracy: 0.8810 - val_loss: 0.3670 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.3658 - accuracy: 0.8810 - val_loss: 0.3615 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 298ms/step - loss: 0.3673 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.3671 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.3738 - accuracy: 0.8810 - val_loss: 0.3607 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.3675 - accuracy: 0.8810 - val_loss: 0.3618 - val_accuracy: 0.8831\n",
      " \n",
      "*************************\n",
      "FOLD 6\n",
      "X_train: (689, 525, 102)\n",
      "y_train: (689, 1)\n",
      "X_valid: (77, 525, 102)\n",
      "y_valid: (77, 1)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 292ms/step - loss: 0.4349 - accuracy: 0.8549 - val_loss: 0.3912 - val_accuracy: 0.8701\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 275ms/step - loss: 0.3650 - accuracy: 0.8824 - val_loss: 0.3885 - val_accuracy: 0.8701\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 8s 271ms/step - loss: 0.3671 - accuracy: 0.8824 - val_loss: 0.3922 - val_accuracy: 0.8701\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 8s 284ms/step - loss: 0.3658 - accuracy: 0.8824 - val_loss: 0.3899 - val_accuracy: 0.8701\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.3637 - accuracy: 0.8824 - val_loss: 0.3874 - val_accuracy: 0.8701\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 0.3652 - accuracy: 0.8824 - val_loss: 0.3894 - val_accuracy: 0.8701\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 8s 276ms/step - loss: 0.3625 - accuracy: 0.8824 - val_loss: 0.3862 - val_accuracy: 0.8701\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 274ms/step - loss: 0.3659 - accuracy: 0.8824 - val_loss: 0.3862 - val_accuracy: 0.8701\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 8s 275ms/step - loss: 0.3647 - accuracy: 0.8824 - val_loss: 0.3874 - val_accuracy: 0.8701\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 7s 251ms/step - loss: 0.3653 - accuracy: 0.8824 - val_loss: 0.3878 - val_accuracy: 0.8701\n",
      " \n",
      "*************************\n",
      "FOLD 7\n",
      "X_train: (690, 525, 102)\n",
      "y_train: (690, 1)\n",
      "X_valid: (76, 525, 102)\n",
      "y_valid: (76, 1)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 294ms/step - loss: 0.4277 - accuracy: 0.8536 - val_loss: 0.3644 - val_accuracy: 0.8816\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 8s 290ms/step - loss: 0.3697 - accuracy: 0.8812 - val_loss: 0.3656 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.3683 - accuracy: 0.8812 - val_loss: 0.3644 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.3665 - accuracy: 0.8812 - val_loss: 0.3656 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 261ms/step - loss: 0.3706 - accuracy: 0.8812 - val_loss: 0.3638 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 6s 231ms/step - loss: 0.3671 - accuracy: 0.8812 - val_loss: 0.3653 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 6s 228ms/step - loss: 0.3691 - accuracy: 0.8812 - val_loss: 0.3639 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 7s 234ms/step - loss: 0.3666 - accuracy: 0.8812 - val_loss: 0.3668 - val_accuracy: 0.8816\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 7s 237ms/step - loss: 0.3652 - accuracy: 0.8812 - val_loss: 0.3663 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 0.3683 - accuracy: 0.8812 - val_loss: 0.3646 - val_accuracy: 0.8816\n",
      " \n",
      "*************************\n",
      "FOLD 8\n",
      "X_train: (690, 525, 102)\n",
      "y_train: (690, 1)\n",
      "X_valid: (76, 525, 102)\n",
      "y_valid: (76, 1)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 9s 259ms/step - loss: 0.4274 - accuracy: 0.8478 - val_loss: 0.3661 - val_accuracy: 0.8816\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 7s 234ms/step - loss: 0.3728 - accuracy: 0.8812 - val_loss: 0.3669 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 7s 239ms/step - loss: 0.3684 - accuracy: 0.8812 - val_loss: 0.3724 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.3706 - accuracy: 0.8812 - val_loss: 0.3651 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 246ms/step - loss: 0.3702 - accuracy: 0.8812 - val_loss: 0.3700 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 7s 241ms/step - loss: 0.3706 - accuracy: 0.8812 - val_loss: 0.3657 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 6s 231ms/step - loss: 0.3700 - accuracy: 0.8812 - val_loss: 0.3639 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 7s 235ms/step - loss: 0.3664 - accuracy: 0.8812 - val_loss: 0.3641 - val_accuracy: 0.8816\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.3708 - accuracy: 0.8812 - val_loss: 0.3675 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 7s 233ms/step - loss: 0.3665 - accuracy: 0.8812 - val_loss: 0.3644 - val_accuracy: 0.8816\n",
      " \n",
      "*************************\n",
      "FOLD 9\n",
      "X_train: (690, 525, 102)\n",
      "y_train: (690, 1)\n",
      "X_valid: (76, 525, 102)\n",
      "y_valid: (76, 1)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 10s 286ms/step - loss: 0.4096 - accuracy: 0.8565 - val_loss: 0.3699 - val_accuracy: 0.8816\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 7s 241ms/step - loss: 0.3679 - accuracy: 0.8812 - val_loss: 0.3640 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 7s 264ms/step - loss: 0.3696 - accuracy: 0.8812 - val_loss: 0.3640 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 7s 242ms/step - loss: 0.3664 - accuracy: 0.8812 - val_loss: 0.3663 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 243ms/step - loss: 0.3680 - accuracy: 0.8812 - val_loss: 0.3665 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 6s 231ms/step - loss: 0.3663 - accuracy: 0.8812 - val_loss: 0.3638 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 6s 229ms/step - loss: 0.3680 - accuracy: 0.8812 - val_loss: 0.3638 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 7s 233ms/step - loss: 0.3692 - accuracy: 0.8812 - val_loss: 0.3638 - val_accuracy: 0.8816\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 7s 236ms/step - loss: 0.3683 - accuracy: 0.8812 - val_loss: 0.3674 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 6s 232ms/step - loss: 0.3651 - accuracy: 0.8812 - val_loss: 0.3693 - val_accuracy: 0.8816\n",
      " \n",
      "*************************\n",
      "FOLD 10\n",
      "X_train: (690, 525, 102)\n",
      "y_train: (690, 1)\n",
      "X_valid: (76, 525, 102)\n",
      "y_valid: (76, 1)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 525, 102)]        0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 100)               81200     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,301\n",
      "Trainable params: 81,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 9s 252ms/step - loss: 0.4270 - accuracy: 0.8652 - val_loss: 0.3641 - val_accuracy: 0.8816\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 7s 235ms/step - loss: 0.3674 - accuracy: 0.8812 - val_loss: 0.3642 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 6s 228ms/step - loss: 0.3662 - accuracy: 0.8812 - val_loss: 0.3782 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 6s 225ms/step - loss: 0.3722 - accuracy: 0.8812 - val_loss: 0.3654 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 7s 251ms/step - loss: 0.3674 - accuracy: 0.8812 - val_loss: 0.3675 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 7s 240ms/step - loss: 0.3675 - accuracy: 0.8812 - val_loss: 0.3639 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 7s 242ms/step - loss: 0.3687 - accuracy: 0.8812 - val_loss: 0.3639 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 8s 278ms/step - loss: 0.3672 - accuracy: 0.8812 - val_loss: 0.3750 - val_accuracy: 0.8816\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 9s 309ms/step - loss: 0.3732 - accuracy: 0.8812 - val_loss: 0.3683 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 8s 286ms/step - loss: 0.3726 - accuracy: 0.8812 - val_loss: 0.3653 - val_accuracy: 0.8816\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_folds = 10\n",
    "cv = StratifiedKFold(n_splits = cv_folds,\n",
    "                     random_state =config.RANDOM_SEED,\n",
    "                     shuffle = True)\n",
    "\n",
    "y_label = np.array(train_labels['basalt'].copy()).reshape((no_samples,1))\n",
    "y_label.shape\n",
    "\n",
    "oof_history = []\n",
    "for fold, (t_, v_) in enumerate(cv.split(data, y_label)):\n",
    "    print('*'*25)\n",
    "    print(f'FOLD {fold+1}')\n",
    "    # Select the training and validation data based\n",
    "    # on the CV method    \n",
    "    X_train = data[t_,:,:]; print(f'X_train: {X_train.shape}')\n",
    "    y_train = y_label[t_,:]; print(f'y_train: {y_train.shape}')\n",
    "    X_valid = data[v_,:,:]; print(f'X_valid: {X_valid.shape}')\n",
    "    y_valid = y_label[v_,:]; print(f'y_valid: {y_valid.shape}')\n",
    "    \n",
    "    # Define model parameters\n",
    "    inputs = layers.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    lstm_out = layers.LSTM(100, dropout=0.2)(inputs)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(lstm_out)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=config.LEARNING_RATE),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    fit_history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_valid, y_valid),\n",
    "                            epochs=config.EPOCHS,\n",
    "                            batch_size=config.BATCH_SIZE,\n",
    "                            verbose=1)\n",
    "    oof_history.append(fit_history)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV loss: 0.36641\n"
     ]
    }
   ],
   "source": [
    "cv_loss = 0\n",
    "for i in range(cv_folds):\n",
    "    cv_loss += np.mean(oof_history[i].history['val_loss'])\n",
    "print(f'Mean CV loss: {np.round(cv_loss/cv_folds,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV loss: 0.36769\n"
     ]
    }
   ],
   "source": [
    "cv_loss = 0\n",
    "for i in range(cv_folds):\n",
    "    cv_loss += np.mean(oof_history[i].history['val_loss'])\n",
    "print(f'Mean CV loss: {np.round(cv_loss/cv_folds,5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 306,
       "width": 887
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = fit_history.history['accuracy']\n",
    "val_acc = fit_history.history['val_accuracy']\n",
    "loss = fit_history.history['loss']\n",
    "val_loss = fit_history.history['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "_,_ = plt.subplots(1,2, figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'b', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'b', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement via CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_osc_time</th>\n",
       "      <th>mz_0_abund</th>\n",
       "      <th>mz_5_abund</th>\n",
       "      <th>mz_6_abund</th>\n",
       "      <th>mz_7_abund</th>\n",
       "      <th>mz_12_abund</th>\n",
       "      <th>mz_13_abund</th>\n",
       "      <th>mz_14_abund</th>\n",
       "      <th>...</th>\n",
       "      <th>mz_92_abund</th>\n",
       "      <th>mz_93_abund</th>\n",
       "      <th>mz_94_abund</th>\n",
       "      <th>mz_95_abund</th>\n",
       "      <th>mz_96_abund</th>\n",
       "      <th>mz_97_abund</th>\n",
       "      <th>mz_98_abund</th>\n",
       "      <th>mz_99_abund</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.198793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.0, 20.0)</td>\n",
       "      <td>35.582467</td>\n",
       "      <td>0.259518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20.0, 30.0)</td>\n",
       "      <td>35.657034</td>\n",
       "      <td>0.191759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30.0, 40.0)</td>\n",
       "      <td>35.796819</td>\n",
       "      <td>0.232425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40.0, 50.0)</td>\n",
       "      <td>35.997046</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>[5200.0, 5210.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>[5210.0, 5220.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>[5220.0, 5230.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>[5230.0, 5240.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>[5240.0, 5250.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0765</td>\n",
       "      <td>sam_testbed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time_bin       temp  temp_osc_time  mz_0_abund  mz_5_abund  \\\n",
       "0         [0.0, 10.0)  35.620765       0.198793         0.0         0.0   \n",
       "1        [10.0, 20.0)  35.582467       0.259518         NaN         0.0   \n",
       "2        [20.0, 30.0)  35.657034       0.191759         NaN         0.0   \n",
       "3        [30.0, 40.0)  35.796819       0.232425         NaN         0.0   \n",
       "4        [40.0, 50.0)  35.997046       0.266277         NaN         0.0   \n",
       "..                ...        ...            ...         ...         ...   \n",
       "520  [5200.0, 5210.0)        NaN            NaN         NaN         NaN   \n",
       "521  [5210.0, 5220.0)        NaN            NaN         NaN         NaN   \n",
       "522  [5220.0, 5230.0)        NaN            NaN         NaN         NaN   \n",
       "523  [5230.0, 5240.0)        NaN            NaN         NaN         NaN   \n",
       "524  [5240.0, 5250.0)        NaN            NaN         NaN         NaN   \n",
       "\n",
       "     mz_6_abund  mz_7_abund  mz_12_abund  mz_13_abund  mz_14_abund  ...  \\\n",
       "0      0.000002    0.000005     0.011006     0.000707     0.001775  ...   \n",
       "1      0.000000    0.000003     0.010468     0.000549     0.001709  ...   \n",
       "2      0.000000    0.000003     0.010033     0.000583     0.001732  ...   \n",
       "3      0.000007    0.000000     0.009330     0.000520     0.001761  ...   \n",
       "4      0.000006    0.000003     0.008610     0.000543     0.001847  ...   \n",
       "..          ...         ...          ...          ...          ...  ...   \n",
       "520         NaN         NaN          NaN          NaN          NaN  ...   \n",
       "521         NaN         NaN          NaN          NaN          NaN  ...   \n",
       "522         NaN         NaN          NaN          NaN          NaN  ...   \n",
       "523         NaN         NaN          NaN          NaN          NaN  ...   \n",
       "524         NaN         NaN          NaN          NaN          NaN  ...   \n",
       "\n",
       "     mz_92_abund  mz_93_abund  mz_94_abund  mz_95_abund  mz_96_abund  \\\n",
       "0       0.000051     0.000046     0.000040     0.000034     0.000183   \n",
       "1       0.000051     0.000034     0.000074     0.000046     0.000143   \n",
       "2       0.000057     0.000046     0.000034     0.000017     0.000143   \n",
       "3       0.000060     0.000060     0.000034     0.000043     0.000137   \n",
       "4       0.000029     0.000057     0.000051     0.000091     0.000154   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "520          NaN          NaN          NaN          NaN          NaN   \n",
       "521          NaN          NaN          NaN          NaN          NaN   \n",
       "522          NaN          NaN          NaN          NaN          NaN   \n",
       "523          NaN          NaN          NaN          NaN          NaN   \n",
       "524          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     mz_97_abund  mz_98_abund  mz_99_abund  sample_id  instrument_type  \n",
       "0       0.000149     0.000131     0.000029      S0765      sam_testbed  \n",
       "1       0.000137     0.000063     0.000017      S0765      sam_testbed  \n",
       "2       0.000109     0.000063     0.000000      S0765      sam_testbed  \n",
       "3       0.000214     0.000077     0.000011      S0765      sam_testbed  \n",
       "4       0.000149     0.000086     0.000017      S0765      sam_testbed  \n",
       "..           ...          ...          ...        ...              ...  \n",
       "520          NaN          NaN          NaN      S0765      sam_testbed  \n",
       "521          NaN          NaN          NaN      S0765      sam_testbed  \n",
       "522          NaN          NaN          NaN      S0765      sam_testbed  \n",
       "523          NaN          NaN          NaN      S0765      sam_testbed  \n",
       "524          NaN          NaN          NaN      S0765      sam_testbed  \n",
       "\n",
       "[525 rows x 97 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht1 = features.dl_time_pivot(metadata, 765, max_time)\n",
    "ht1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht1.time_bin.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 116422\n",
      "Ion rows: 1\n"
     ]
    }
   ],
   "source": [
    "ht = preprocess.get_sample(metadata, 765)\n",
    "ht = preprocess.preprocess_samples(ht)\n",
    "\n",
    "print(f'Rows: {ht.shape[0]}')\n",
    "print(f'Ion rows: {ht.groupby(\"m/z\")[\"m/z\"].agg(\"count\").unique()[0]}')\n",
    "\n",
    "time_range = pd.interval_range(start=0.0, \n",
    "                               end=utils.roundup(max_time), \n",
    "                               freq=10, \n",
    "                               closed='left')\n",
    "ht['time_bin'] = pd.cut(ht['time'], bins=time_range)\n",
    "del ht['time']\n",
    "#ht.sort_values(['m/z', 'time_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48300, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m/z</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>temp</th>\n",
       "      <th>abun_minsub_scaled</th>\n",
       "      <th>temp_osc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>6.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>12.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>13.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>14.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>16.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>17.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.271100</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>18.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.995289</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>19.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>20.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6825</th>\n",
       "      <td>21.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>22.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>23.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>24.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>25.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>26.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>27.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.014081</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>28.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.136359</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11025</th>\n",
       "      <td>29.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>30.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12075</th>\n",
       "      <td>31.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>32.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13125</th>\n",
       "      <td>33.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650</th>\n",
       "      <td>34.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>35.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14700</th>\n",
       "      <td>36.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>37.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15750</th>\n",
       "      <td>38.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>39.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16800</th>\n",
       "      <td>40.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>41.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17850</th>\n",
       "      <td>42.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18375</th>\n",
       "      <td>43.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>44.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.475849</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19425</th>\n",
       "      <td>45.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>46.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>47.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21000</th>\n",
       "      <td>48.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21525</th>\n",
       "      <td>49.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22050</th>\n",
       "      <td>50.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22575</th>\n",
       "      <td>51.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23100</th>\n",
       "      <td>52.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23625</th>\n",
       "      <td>53.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24150</th>\n",
       "      <td>54.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24675</th>\n",
       "      <td>55.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25200</th>\n",
       "      <td>56.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25725</th>\n",
       "      <td>57.0</td>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>35.620765</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.198793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        m/z     time_bin       temp  abun_minsub_scaled  temp_osc\n",
       "0       0.0  [0.0, 10.0)  35.620765            0.000000  0.198793\n",
       "525     5.0  [0.0, 10.0)  35.620765            0.000000  0.198793\n",
       "1050    6.0  [0.0, 10.0)  35.620765            0.000002  0.198793\n",
       "1575    7.0  [0.0, 10.0)  35.620765            0.000005  0.198793\n",
       "2100   12.0  [0.0, 10.0)  35.620765            0.011006  0.198793\n",
       "2625   13.0  [0.0, 10.0)  35.620765            0.000707  0.198793\n",
       "3150   14.0  [0.0, 10.0)  35.620765            0.001775  0.198793\n",
       "3675   15.0  [0.0, 10.0)  35.620765            0.009124  0.198793\n",
       "4200   16.0  [0.0, 10.0)  35.620765            0.055259  0.198793\n",
       "4725   17.0  [0.0, 10.0)  35.620765            0.271100  0.198793\n",
       "5250   18.0  [0.0, 10.0)  35.620765            0.995289  0.198793\n",
       "5775   19.0  [0.0, 10.0)  35.620765            0.019529  0.198793\n",
       "6300   20.0  [0.0, 10.0)  35.620765            0.001349  0.198793\n",
       "6825   21.0  [0.0, 10.0)  35.620765            0.000011  0.198793\n",
       "7350   22.0  [0.0, 10.0)  35.620765            0.002887  0.198793\n",
       "7875   23.0  [0.0, 10.0)  35.620765            0.000017  0.198793\n",
       "8400   24.0  [0.0, 10.0)  35.620765            0.000217  0.198793\n",
       "8925   25.0  [0.0, 10.0)  35.620765            0.000503  0.198793\n",
       "9450   26.0  [0.0, 10.0)  35.620765            0.003522  0.198793\n",
       "9975   27.0  [0.0, 10.0)  35.620765            0.014081  0.198793\n",
       "10500  28.0  [0.0, 10.0)  35.620765            0.136359  0.198793\n",
       "11025  29.0  [0.0, 10.0)  35.620765            0.004213  0.198793\n",
       "11550  30.0  [0.0, 10.0)  35.620765            0.002127  0.198793\n",
       "12075  31.0  [0.0, 10.0)  35.620765            0.000875  0.198793\n",
       "12600  32.0  [0.0, 10.0)  35.620765            0.003659  0.198793\n",
       "13125  33.0  [0.0, 10.0)  35.620765            0.000703  0.198793\n",
       "13650  34.0  [0.0, 10.0)  35.620765            0.000297  0.198793\n",
       "14175  35.0  [0.0, 10.0)  35.620765            0.000091  0.198793\n",
       "14700  36.0  [0.0, 10.0)  35.620765            0.000103  0.198793\n",
       "15225  37.0  [0.0, 10.0)  35.620765            0.000337  0.198793\n",
       "15750  38.0  [0.0, 10.0)  35.620765            0.000537  0.198793\n",
       "16275  39.0  [0.0, 10.0)  35.620765            0.002927  0.198793\n",
       "16800  40.0  [0.0, 10.0)  35.620765            0.001789  0.198793\n",
       "17325  41.0  [0.0, 10.0)  35.620765            0.005568  0.198793\n",
       "17850  42.0  [0.0, 10.0)  35.620765            0.002424  0.198793\n",
       "18375  43.0  [0.0, 10.0)  35.620765            0.002321  0.198793\n",
       "18900  44.0  [0.0, 10.0)  35.620765            0.475849  0.198793\n",
       "19425  45.0  [0.0, 10.0)  35.620765            0.006369  0.198793\n",
       "19950  46.0  [0.0, 10.0)  35.620765            0.002407  0.198793\n",
       "20475  47.0  [0.0, 10.0)  35.620765            0.000692  0.198793\n",
       "21000  48.0  [0.0, 10.0)  35.620765            0.002487  0.198793\n",
       "21525  49.0  [0.0, 10.0)  35.620765            0.000223  0.198793\n",
       "22050  50.0  [0.0, 10.0)  35.620765            0.001366  0.198793\n",
       "22575  51.0  [0.0, 10.0)  35.620765            0.000886  0.198793\n",
       "23100  52.0  [0.0, 10.0)  35.620765            0.000743  0.198793\n",
       "23625  53.0  [0.0, 10.0)  35.620765            0.000349  0.198793\n",
       "24150  54.0  [0.0, 10.0)  35.620765            0.000309  0.198793\n",
       "24675  55.0  [0.0, 10.0)  35.620765            0.001138  0.198793\n",
       "25200  56.0  [0.0, 10.0)  35.620765            0.003047  0.198793\n",
       "25725  57.0  [0.0, 10.0)  35.620765            0.001149  0.198793"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_agg = ht.groupby(['m/z', 'time_bin']).agg('mean').reset_index()\n",
    "print(ht_agg.shape)\n",
    "ht_agg['temp_osc'] = ht_agg.groupby('time_bin')['temp'].transform('std')\n",
    "ht_agg['temp'] = ht_agg.groupby('time_bin')['temp'].transform('mean')\n",
    "ht_agg[ht_agg['time_bin'] == pd.Interval(0.0, 10.0, closed=('left'))].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 116422\n",
      "Ion rows: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin</th>\n",
       "      <th>m/z</th>\n",
       "      <th>temp_agg</th>\n",
       "      <th>abun_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.285714</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.142857</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 10.0)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.011006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141240</th>\n",
       "      <td>[4200.0, 4210.0)</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141241</th>\n",
       "      <td>[4200.0, 4210.0)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141242</th>\n",
       "      <td>[4200.0, 4210.0)</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141243</th>\n",
       "      <td>[4200.0, 4210.0)</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141244</th>\n",
       "      <td>[4200.0, 4210.0)</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37794 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_bin   m/z     temp_agg  abun_agg\n",
       "0            [0.0, 10.0)   0.0    36.000000  0.000000\n",
       "1            [0.0, 10.0)   5.0    35.142857  0.000000\n",
       "2            [0.0, 10.0)   6.0    35.285714  0.000009\n",
       "3            [0.0, 10.0)   7.0    35.142857  0.000009\n",
       "4            [0.0, 10.0)  12.0    35.500000  0.011006\n",
       "...                  ...   ...          ...       ...\n",
       "141240  [4200.0, 4210.0)  95.0  1048.000000  0.000017\n",
       "141241  [4200.0, 4210.0)  96.0  1046.000000  0.000017\n",
       "141242  [4200.0, 4210.0)  97.0  1048.000000  0.000069\n",
       "141243  [4200.0, 4210.0)  98.0  1048.000000  0.000034\n",
       "141244  [4200.0, 4210.0)  99.0  1048.000000  0.000017\n",
       "\n",
       "[37794 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = preprocess.get_sample(metadata, 765)\n",
    "ht = preprocess.preprocess_samples(ht)\n",
    "\n",
    "print(f'Rows: {ht.shape[0]}')\n",
    "print(f'Ion rows: {ht.groupby(\"m/z\")[\"m/z\"].agg(\"count\").unique()[0]}')\n",
    "\n",
    "time_range = pd.interval_range(start=0.0, \n",
    "                               end=utils.roundup(max_time), \n",
    "                               freq=10, \n",
    "                               closed='left')\n",
    "ht['time_bin'] = pd.cut(ht['time'], bins=time_range)\n",
    "ht = ht[['time_bin', 'temp', 'm/z', 'abun_minsub_scaled']]\n",
    "\n",
    "\n",
    "ht['temp'] = np.round(ht['temp'],0)\n",
    "ht['temp_agg'] = ht.groupby(['time_bin', 'm/z'])['temp'].transform('mean')\n",
    "del ht['temp']\n",
    "ht.drop_duplicates(inplace=True)\n",
    "ht['abun_agg'] = ht.groupby(['time_bin', 'temp_agg', 'm/z'])['abun_minsub_scaled']\\\n",
    "            .transform('mean')\n",
    "del ht['abun_minsub_scaled']\n",
    "ht.drop_duplicates(inplace=True)\n",
    "    \n",
    "ht.head()\n",
    "#ht.head(25)\n",
    "ht.sort_values(['time_bin', 'm/z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa1bb730ddeebc089519bcd4ec0e31841e14f65d7c169a2b301ba6e4e1462a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nasamars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
