{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "## Environment\n",
    "# Change main system path to be able to run code from src folder\n",
    "import sys\n",
    "p = sys.path[0]\n",
    "# Mac OS\n",
    "if sys.path[0].endswith('/models'):\n",
    "    main_path = p[:-len('/models')]\n",
    "sys.path[0] = main_path\n",
    "\n",
    "import os, gc\n",
    "from termcolor import colored\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from src import (config, fe, features, feature_selection, \n",
    "                 preprocess, training)\n",
    "from src.fe import CreateFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (1570, 5)\n",
      "Train labels: (766, 11)\n",
      "Train labels: (293, 11)\n",
      "Submission: (804, 11)\n",
      "['basalt', 'carbonate', 'chloride', 'iron_oxide', 'oxalate', 'oxychlorine', 'phyllosilicate', 'silicate', 'sulfate', 'sulfide']\n",
      "Labels w/o SAM : (1047, 11)\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION\n",
    "# ===== LOAD DATA ======\n",
    "metadata = pd.read_csv(config.DATA_DIR + 'metadata.csv')\n",
    "print(f'Metadata: {metadata.shape}')\n",
    "\n",
    "train_labels = pd.read_csv(config.DATA_DIR + 'train_labels.csv')\n",
    "print(f'Train labels: {train_labels.shape}')\n",
    "\n",
    "valid_labels = pd.read_csv(config.DATA_DIR + 'val_labels.csv')\n",
    "print(f'Train labels: {valid_labels.shape}')\n",
    "\n",
    "# Combine train and valid labels\n",
    "trvl_labels = pd.concat([train_labels, valid_labels], axis = 0)\n",
    "\n",
    "submission = pd.read_csv(config.DATA_DIR + 'submission_format.csv')\n",
    "print(f'Submission: {submission.shape}')\n",
    "\n",
    "# ===== FILE PATHS OF SAMPLES =====\n",
    "train_files = metadata[metadata.split == 'train']['features_path'].to_dict()\n",
    "valid_files = metadata[metadata.split == 'val']['features_path'].to_dict()\n",
    "test_files = metadata[metadata.split == 'test']['features_path'].to_dict()\n",
    "# Train & Valid files\n",
    "trva_files = train_files.copy()\n",
    "trva_files.update(valid_files)\n",
    "# All files\n",
    "all_test_files = valid_files.copy()\n",
    "all_test_files.update(test_files)\n",
    "\n",
    "# Define SAM testbed files\n",
    "sam_files = metadata[(metadata.instrument_type == 'sam_testbed') & (metadata.split == 'train')]['features_path']\n",
    "sam_files = sam_files.to_dict()\n",
    "\n",
    "# Get the names of the target columns in a list\n",
    "target_labels_list = [i for i in train_labels.columns if i not in ['sample_id']]\n",
    "print(target_labels_list)\n",
    "\n",
    "# SAM testbed labels\n",
    "sam_labels = train_labels.drop(train_labels.tail(len(sam_files)).index)\n",
    "sam_labels = pd.concat([sam_labels, valid_labels], axis=0)\n",
    "print(f'Labels w/o SAM : {sam_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTS_NAME = 'fts_mra_tempmz_slope_cntpk'      # Name of the file with base features\n",
    "COMPUTE_FTS = True                           # Should the features be recomputed\n",
    "COMPUTE_FTS_SAM = False                      # Compute SAM test bed\n",
    "MODEL_ALGO = 'XGB_opt'                       # Name of the classifier\n",
    "MODEL_NAME = FTS_NAME + '_' + MODEL_ALGO     # Name of the model\n",
    "FTS_SELECT = True\n",
    "COMBINE_FTS = ['fts_mra_tempmz', 'fts_slope_tt', 'fts_cntpk_mratt']\n",
    "SFM_MODEL = 'fts_mra_tempmz_slope_XGB_opt'\n",
    "SFM_FEATURE = 'fts_mra_tempmz_slope'\n",
    "ADD_FEATURE = ['fts_cntpk_mratt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPUTE FEATURES**\n",
    "\n",
    "- Change the `fe._` method depending on the feature that we wish to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features ... \n",
      "\u001b[34mtrain => (766, 1981)\u001b[0m\n",
      "\u001b[34mtrain => (1059, 1981)\u001b[0m\n",
      "\u001b[34mtrain => (804, 1981)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if feature is computed and load it or choose to compute it\n",
    "check_file = 0\n",
    "for i in ['_tr', '_trvl', '_vlte']:\n",
    "    check_file += os.path.exists(os.path.join(config.DATA_DIR_OUT, FTS_NAME +\n",
    "                                              str(i) + '.csv'))\n",
    "\n",
    "if (check_file == 3) & (not COMPUTE_FTS):\n",
    "    print('Reading features ... ')\n",
    "    X_tr = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_tr.csv'))\n",
    "    print(X_tr.shape)\n",
    "    X_trvl = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_trvl.csv'))\n",
    "    print(X_trvl.shape)\n",
    "    X_vlte = pd.read_csv(os.path.join(config.DATA_DIR_OUT, FTS_NAME + '_vlte.csv'))\n",
    "    print(X_vlte.shape)\n",
    "    \n",
    "else:\n",
    "    print('Computing features ... ')\n",
    "    # ----- TRAIN -----\n",
    "    fe = CreateFeatures(metadata, train_files, 'tr', FTS_NAME)\n",
    "    X_tr = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_tr.shape}', 'blue'))\n",
    "    \n",
    "    # ----- TRAIN & VALID -----\n",
    "    fe = CreateFeatures(metadata, trva_files, 'trvl', FTS_NAME)\n",
    "    X_trvl = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_trvl.shape}', 'blue'))\n",
    "    \n",
    "    # ----- VALID & TEST -----\n",
    "    fe = CreateFeatures(metadata, all_test_files, 'vlte', FTS_NAME)\n",
    "    X_vlte = fe.combine_features(COMBINE_FTS)\n",
    "    print(colored(f'train => {X_vlte.shape}', 'blue'))\n",
    "    \n",
    "if COMPUTE_FTS_SAM:\n",
    "    print(f'\\nCreating SAM testbed samples ...')\n",
    "    # Training without SAM testbed\n",
    "    X_tr_sam = X_tr.drop(X_tr.tail(len(sam_files)).index).copy()\n",
    "    X_tr_sam = pd.concat([X_tr_sam, X_trvl.iloc[len(train_files):,:]], axis=0)\n",
    "    print(f'Train shape: {X_tr_sam.shape}')\n",
    "    # Validation data\n",
    "    X_vl_sam = X_tr.tail(len(sam_files)).copy()\n",
    "    print(f'Valid shape: {X_vl_sam.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading columns from ../models/fts_mra_tempmz_slope_tr_SFM_COLS.txt\n",
      "Adding new columns from fts_cntpk_mratt\n",
      "\n",
      "NO FETAURES PER TARGET\n",
      "basalt: 428\n",
      "carbonate: 523\n",
      "chloride: 441\n",
      "iron_oxide: 556\n",
      "oxalate: 404\n",
      "oxychlorine: 427\n",
      "phyllosilicate: 642\n",
      "silicate: 1980\n",
      "sulfate: 486\n",
      "sulfide: 471\n"
     ]
    }
   ],
   "source": [
    "# Use precomputed model features and add the features of the current \n",
    "# data set\n",
    "if FTS_SELECT:\n",
    "    _, SFM_COLUMNS = feature_selection.fts_select(\n",
    "        target_labels_list, SFM_FEATURE, SFM_MODEL, MODEL_ALGO, 'tr',\n",
    "        X_tr, X_vlte, train_labels, valid_files, valid_labels\n",
    "    )\n",
    "else:\n",
    "    SFM_COLUMNS = None\n",
    "    \n",
    "# Add columns from a new data set \n",
    "if (ADD_FEATURE and (len(ADD_FEATURE) > 0)):\n",
    "    new_features = []\n",
    "    for i in ADD_FEATURE:\n",
    "        print(f'Adding new columns from {i}')\n",
    "        fts_path = os.path.join(config.DATA_DIR_OUT,\n",
    "                            str(i) + '_tr.csv')\n",
    "        if os.path.exists(fts_path):\n",
    "            df = pd.read_csv(fts_path)\n",
    "            new_features.extend(df.columns)\n",
    "        else:\n",
    "            print(colored(f'No file {i}', 'red'))\n",
    "for i in SFM_COLUMNS:\n",
    "    SFM_COLUMNS[i].extend(new_features)\n",
    "    \n",
    "print('\\nNO FETAURES PER TARGET')\n",
    "for label in target_labels_list:\n",
    "    print(f'{label}: {len(SFM_COLUMNS[label])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCV training ....\u001b[0m\n",
      "\u001b[35mbasalt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mcarbonate\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/Users/itacdonev/opt/miniconda3/envs/nasamars/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN =====\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr,\n",
    "    df_labels=train_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_tr',\n",
    "    fts_select_cols=SFM_COLUMNS,\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               valid_files, valid_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_tr',\n",
    "                                               fts_select_cols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Logloss: {np.mean(list(cvloss.values()))}')\n",
    "print(f'VALID FM LogLoss: {mloss_avg}')\n",
    "print(f'CV logLoss Label')\n",
    "print(cvloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THE SFM_COLUMNS based on the trained model\n",
    "# CV loss method: 1 feature added and compute the diff in logloss\n",
    "# SFM method: > 1 feature and recompute SFM.\n",
    "cols_to_remove = feature_selection.update_fts_columns(target_labels_list,\n",
    "                        SFM_MODEL,\n",
    "                        'tr', \n",
    "                        cvloss, \n",
    "                        new_features)\n",
    "\n",
    "# Update feature dictionary and save to file\n",
    "SFM_COLUMNS = feature_selection.remove_cols(SFM_COLUMNS, \n",
    "                                            cols_to_remove, \n",
    "                                            target_labels_list)\n",
    "\n",
    "# Save features\n",
    "feature_selection.save_features(FTS_NAME, 'tr', SFM_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN & VALID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, SFM_COLUMNS = feature_selection.fts_select(\n",
    "    target_labels_list, FTS_NAME, MODEL_NAME, 'trvl',\n",
    "    X_tr, X_vlte, train_labels, valid_files, valid_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRAIN =====\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_trvl,\n",
    "    df_labels=trvl_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vlte,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_trvl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Logloss: {np.mean(list(cvloss.values()))}')\n",
    "print(f'CV logLoss Label')\n",
    "print(cvloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAM TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== TRAIN SAM =====\n",
    "cvloss, submission_model = training.train_tbl(\n",
    "    df_train=X_tr_sam,\n",
    "    df_labels=sam_labels,\n",
    "    target_list=target_labels_list,\n",
    "    df_test=X_vl_sam,\n",
    "    model_algo=MODEL_ALGO,\n",
    "    sub_name=MODEL_NAME + '_sam',\n",
    "    test_sam=True\n",
    "    )\n",
    "\n",
    "# Compute validation loss when full model is trained\n",
    "mloss, mloss_avg = training.compute_valid_loss(submission_model,\n",
    "                                               sam_files, sam_labels,\n",
    "                                               target_labels_list,\n",
    "                                               sub_name=MODEL_NAME + '_sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Logloss: {np.mean(list(cvloss.values()))}')\n",
    "print(f'VALID FM LogLoss: {mloss_avg}')\n",
    "print(f'CV logLoss Label')\n",
    "print(cvloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cfa1bb730ddeebc089519bcd4ec0e31841e14f65d7c169a2b301ba6e4e1462a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nasamars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
